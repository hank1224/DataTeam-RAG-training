{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG Implementation with LlamaIndex - V2\n",
    "\n",
    "https://docs.llamaindex.ai/en/stable/examples/cookbooks/GraphRAG_v2/\n",
    "\n",
    "## 失敗：build_communities() 被 Azuer OpenAI 暴力內容被擋下來\n",
    "\n",
    "BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "# import logging\n",
    "# import sys\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     stream=sys.stdout, level=logging.INFO\n",
    "# )  # logging.DEBUG for more verbose output\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "gpt4o = AzureOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    deployment_name=os.environ[\"MY_AZURE_OPENAI_DEPLOYMENT_NAME_CHAT\"], \n",
    "    api_key=os.environ[\"MY_AZURE_OPENAI_API_KEY\"],\n",
    "    azure_endpoint=os.environ[\"MY_AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    deployment_name=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME_EMBEDDINGS\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = gpt4o\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='fa2059b0-a8e9-4c38-9311-e50201f58886', embedding=None, metadata={'file_path': 'data/90-Romance-of-the-Three-Kingdoms.txt', 'file_name': '90-Romance-of-the-Three-Kingdoms.txt', 'file_type': 'text/plain', 'file_size': 20175, 'creation_date': '2025-01-16', 'last_modified_date': '2025-01-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='第九十回：驅巨獸六破蠻兵，燒藤甲七擒孟獲\\n卻說孔明放了孟獲等一干人，楊鋒父子皆封官爵，重賞洞兵。楊鋒等拜謝而去。孟獲等連夜奔回銀坑洞。那洞外有三江：乃是瀘水、甘南水、西城水。三路水會合，故為三江。其洞北近平坦二百餘里，多產萬物；洞西二百餘里，有鹽井；西南二百里，直抵瀘、甘；正南三百里，乃是梁都洞。洞中有山，環抱其洞；山上出銀礦，故名為銀坑山。山中置宮殿樓臺，以為蠻王巢穴。\\n其中建一祖廟，名曰「家鬼」。四時殺牛宰馬享祭。名曰「卜鬼」。每年常以蜀人并外鄉之人祭之。若人患病，不肯服藥，只禱師巫，名為「藥鬼。」其處無刑法，但犯罪即斬。有女長成，卻於溪中沐浴，男女自相混淆，任其自配，父母不禁，名為「學藝」。年歲雨水均調，則種稻穀；倘若不熟，殺蛇為羹，煮象為飯。每方隅之中，上戶號曰：「洞主」，次日「酋長」。每月初一十五兩日，皆在三江城中買賣，轉易貨物。其風俗如此。\\n卻說孟獲在洞中，聚集宗黨千餘人，謂之曰：「吾屢受辱於蜀兵，立誓欲報之。汝等有何高見？」言未畢，一人應曰：「吾舉一人，可破諸葛亮。」眾視之，乃孟獲妻弟，現為八番部長，名曰「帶來洞主」。\\n獲大喜，急問何人。帶來洞主曰：「此去西南八納洞，洞主木鹿大王，深通法術：出則騎象；能呼風喚雨；常有虎報豺狼、毒蛇惡蝎跟隨。手下更有三萬神兵，甚是英勇。大王可修書具禮，某親往求之。此人若允，何懼蜀兵哉？」獲忻然，令國舊齎書而去。卻令朵思大王守把三江城，以為前面屏障。\\n卻說孔明提兵直至三江城，遙望見此城三面傍江，一面通旱；即遣魏延、趙雲同嶺一軍於旱路打城。軍到城下時，城上弓弩齊發。原來洞中之人，多習弓弩。一弩齊發十矢；箭頭上皆用毒藥；但有中箭者，皮肉皆爛，見五臟而死。\\n趙雲、魏延不能取勝，回見孔明言藥箭之事。孔明自乘小車，到軍前看了虛實，回到寨中，令軍退數里下寨。蠻兵望見蜀兵遠退，皆大笑作賀，只疑蜀兵懼怯而退；因此夜間安心穩睡，不去哨探。\\n卻說孔明約軍退後，即閉寨不出。一連五日。並無號令。黃昏左側，忽起微風。孔明傳令曰：「每軍要衣襟一幅，限一更時分應點。無者立斬。」諸將皆不知其意，只得依令預備。孔明又傳令曰：「諸軍包土，俱在三江城下交割。先到者有賞。」\\n眾軍聞令，皆包淨土，飛奔城下。孔明令積土為蹬道，先上城者為頭功。於是蜀兵十餘萬，并降兵萬餘，將所包之土，一齊棄於城下。一霎時，積土成山，接連城上。一聲暗號，蜀兵皆上城。蠻兵急放弩時，大半早被執下。餘者棄城而走。朵思大王死於亂軍之中。蜀將督軍分路剿殺。孔明取了三江城。所得珍寶，皆賞三軍。殘敗蠻兵逃回見孟獲，說：「朵思大王身死，失了三江城。」獲大驚。\\n正慮之間，人報蜀兵以度江，見在本洞前下寨。孟獲甚是慌張。忽然屏後一人大笑而出曰：「既為男子，何無智也？我雖是一婦人，願與你出戰。」獲視之，乃妻祝融夫人也。夫人世居南蠻，乃祝融氏之後；善使飛刀，百發百中。孟獲起身稱謝。夫人忻然上馬，引宗黨猛將數百員，生力洞兵五萬，出銀坑宮闕，來與蜀兵對敵。\\n方纔轉過洞口，一彪軍攔住，為首蜀將，乃是張嶷。蠻兵見之，卻早兩路擺開。祝融夫人背插五口飛刀，手挺丈八長標，坐下捲毛赤兔馬。張嶷見之，暗暗稱奇。二人驟馬交鋒。戰不數合，夫人撥馬便走。張嶷趕去，空中一把飛刀落下。嶷急用手隔，正中左臂，翻身落馬。蠻兵發一聲喊，將張嶷執縛去了。\\n馬忠聽得張嶷被執，急出救時，早被蠻兵困住。望見祝融夫人挺標勒馬而立，忠忿怒向前去戰，坐下馬絆倒，亦被擒了。都解人洞中來見孟獲。獲設席慶賀。夫人叱刀斧手推出張嶷、馬忠要斬。獲止曰：「諸葛亮放吾五次，今番若斬彼將，是不義也。且囚在洞中，待擒住諸葛亮，殺之未遲。」夫人從其言，笑飲作樂。\\n卻說敗殘兵來見孔明，告知其事。孔明即喚馬岱、趙雲、魏延三人受計。各自領軍前去。次日，蠻兵報入洞中，說趙雲搦戰。祝融夫人即上馬出迎。二人戰不數合，雲撥馬便走。夫人恐有埋伏，勒兵而回。延又引軍來搦戰，夫人縱馬相迎。正交鋒緊急，延詐敗而逃，夫人只不趕。\\n次日，趙雲又引軍來搦戰，夫人領洞兵出迎。二人戰不數合，雲詐敗而走，夫人案標不趕。欲收兵回洞時，魏延引軍齊聲辱罵，夫人急挺標來取魏延。延撥馬便走。夫人忿趕怒來，延驟馬奔入山僻小路，忽然背後一聲響亮，延回頭視之，夫人仰鞍落馬。\\n原來馬岱埋伏在此，用絆馬索絆倒，就裏擒縛，解投大寨而來。蠻將洞兵皆來救時，趙雲一陣殺散。孔明端坐於帳上。馬岱解祝融夫人到，孔明即令武士去其縛，請在別帳賜酒壓驚，遣使往告孟獲，欲送夫人換張嶷、馬忠二將。\\n孟獲允諾，即放出張嶷、馬忠，還了孔明。孔明遂送夫人入洞。孟獲接著，又喜又惱。忽報八納洞主到。孟獲出帳迎接，見其人騎著白象，身穿金珠瓔絡，腰懸兩口大刀，領著一班餵養虎豹豺狼之士簇擁而入。獲再拜哀告，訴說前事。木鹿大王許以報讎。獲大喜，設宴相待。\\n次日，木鹿大王引本洞帶猛獸而出。趙雲、魏延聽知蠻兵出，遂將軍馬布成陣勢。二將並轡立於陣前視之，只見蠻兵旗幟器械皆別；人多不穿衣甲，盡裸身赤體，面目醜陋；身帶四把尖刀；軍中不鳴鼓角，但篩金為號；木鹿大王腰挂兩把寶刀，手執蒂鐘，身騎白象，從大旗中而出。趙雲見了魏延曰：「我等上陣一生，未嘗見如此人物。」\\n二人正沉吟之際，只見木鹿大王口中不知念甚咒語，手搖蒂鐘。忽然狂風大作，飛砂走石，如同驟雨，一聲畫角響，虎豹豺狼，猛獸毒蛇，乘風而出，張牙五爪，衝將過來。蜀兵如何抵當，往後便退。蠻兵隨後追殺，直趕到三江界路方回。趙雲、魏延收聚敗兵，來孔明帳前請罪，細說此事。\\n孔明笑曰：「非汝二人之罪。吾未出茅廬之時，先知南蠻有『驅虎豹』之法。吾在蜀中已辦下破此陣之物也。隨軍有二十輛車。俱封記在此。今日且用一半，留下一半，後有別用。」遂令左右取了十輛紅油櫃車到帳下，留十輛黑油櫃車在後。眾皆不知其意。孔明將櫃打開，皆是木刻綵畫巨獸，俱用五色絨線為毛衣，鋼鐵為牙爪，一個可騎坐十人。孔明選了精壯軍士一千餘人，領了一百口，內裝煙火之物，藏在車中。次日，孔明驅兵大進，布於洞口。蠻兵探知，入洞報與蠻王。木鹿大王自謂無敵，即與孟獲引洞兵而出。孔明綸巾羽扇，身衣道袍，端坐於車上。孟獲指曰：「車上坐的便是諸葛亮！若擒住此人，大事定矣！」木鹿大王口中念咒，手搖蒂鐘。頃刻之間，狂風大作，猛獸突出。孔明將羽扇一搖，其風便回吹彼陣中去了。蜀陣中假獸擁出。蠻洞真獸見蜀陣巨獸口吐火焰，鼻出黑煙。身搖銅鈴，張牙舞爪而來，諸惡獸不敢前進，皆奔回蠻洞，反將蠻兵衝倒無數。孔明驅兵大進，鼓角齊鳴，望前追殺。木鹿大王死於亂軍之中。洞內孟獲宗黨，皆棄宮闕，扒山越領而走。孔明大軍占了銀坑洞。\\n次日，孔明正要分兵緝擒孟獲，忽報：「蠻王孟獲妻弟帶來洞主，因勸孟獲歸降，獲不從，今將孟獲並祝融夫人及宗黨數百餘人盡皆擒來，獻與丞相。」\\n孔明聽知，即喚張嶷、馬忠，分付如此如此。二將受了計，引二千精壯兵，伏於兩廊。孔明即令守門將，俱放進來。帶來洞主引刀斧手解孟獲等數百人，拜於殿下。孔明大喝曰：「與吾擒下！」兩廊壯兵齊出，二人捉一人，盡被執縛。孔明大笑曰：「量汝些小詭計，如何瞞得過我！汝見二次俱是本洞人擒汝來降，吾不加害汝，只道吾深信，故來詐降，欲就洞中殺吾！」喝令武士搜其身畔，果然各帶利刀。\\n孔明問孟獲曰：「汝原說在汝家擒住，方始心服；今日如何？」獲曰：「此是我等自來送死，非汝之能也。吾心未服。」孔明曰：「吾擒住六番，尚然不服，欲待何時耶？」獲曰：「汝第七次擒住，吾方傾心歸服，誓不反矣。」孔明曰：「巢穴已破，吾何慮哉？」令武士盡去其縛，叱之曰：「這番擒住，再若支吾，必不輕恕！」孟獲等抱頭鼠竄而去。\\n卻說敗殘蠻兵有千餘人，大半中傷而逃，正遇蠻王孟獲。獲收了敗兵，心中稍喜，卻與帶來洞主商議曰：「吳今洞府已被蜀兵所占，今投何地安身？」帶來洞主曰：「止有一國可以破蜀。」獲喜曰：「何處可去？」帶來洞主曰：「此去東南七百里，有一國名烏戈國。國主兀突骨，身長二丈，不食五榖，以生蛇惡獸為飯；身有鱗甲，刀劍不能侵。其手下軍士。俱穿藤甲；其藤生於山澗之中，盤於石壁之內；國人採取浸於油中，半年方取出晒之；晒乾復浸，凡十餘遍，卻纔造成鎧甲，穿在身上，渡江不沉，經水不濕，刀箭皆不能入。因此號為『藤甲軍』。今大王可往求之。若得彼相助，擒諸葛亮如利刀破竹也。」\\n孟獲大喜，遂投烏戈國，來見兀突骨。其洞無宇舍，皆居土穴之內。孟獲入洞，再拜哀告前事。兀突骨曰：「吾起洞之兵，與汝報讎。」獲欣然拜謝。於是兀突骨喚兩個領兵俘長：一名土安，一名奚泥；起三萬兵，皆穿藤甲，離烏戈國望東北而來。行至一江，名桃花水。兩岸有桃樹，歷年落葉於水中，若別國人飲之盡死；惟烏戈國人飲之，倍添精神。兀突骨兵至桃花渡口下寨，以待蜀兵。\\n卻說孔明令蠻人哨探孟獲消息，回報曰：「孟獲請烏戈國主，引三萬藤甲軍，見屯於桃花渡口。孟獲又在各番聚集蠻兵，併力拒戰。」孔明聽說，提兵大進，直至桃花渡口，隔岸望見蠻兵不類人形，甚是醜惡；又問土人，言說即日桃葉正落，水不可飲。孔明退五里下寨，留魏嚴守寨。\\n次日，烏戈國主引一彪藤甲軍過河來，金鼓大震。魏延引兵出迎。蠻兵捲地而至。蜀兵以弩箭射到藤甲之上，皆不能透，俱落於地；刀砍鎗刺，亦不能入。蠻兵皆使利刀剛叉，蜀兵如何抵當，盡皆敗走。蠻兵不趕而回。魏延復回。趕到桃花渡口，只見蠻兵帶甲渡水而去內有困乏者，將甲脫下，放在水面，以身坐其上而渡。魏延急回大寨，來稟孔明，細言其事。孔明請呂凱并土人問之。凱曰：「某素聞南蠻中有一烏戈國，無人倫者也。更有藤甲護身，急切難傷。又有桃葉惡水，本國人飲之，反添精神；別國人飲之，即死。如此蠻方，縱使全勝，有何益焉？不如班師早回。」孔明笑曰：「吾非容易到此，豈可便去？吾明日自有平蠻之策。」於是令趙雲助魏延守寨，且休輕出。\\n次日，孔明令土人引路，自乘小車到桃花渡口北岸山僻去處，遍觀地理。山險嶺峻之處，車不能行，孔明棄車步行。忽到一山，望見一谷，形如長蛇，皆危峭石壁，並無樹木，中間一條大路。孔明問土人曰：「此谷何名？」土人答曰：「此處名為盤蛇谷。出谷則三江城大路。谷前名塔郎甸。」孔明大喜曰：「此乃天賜吾成功於此也！」遂回舊路，上車歸寨，喚馬岱分付曰：「與汝黑油櫃車十輛，須用竹竿千條。櫃內之物，如此如此。可將本部兵去把住盤蛇谷兩頭依法而行。與汝半月限，一切完備。至期如此施設。倘有走漏，定按軍法。」\\n馬岱受計而去。又喚趙雲分付曰：「汝去盤蛇谷後，三江大路口如此守把。所用之物，剋日完備。」趙雲受計而去。又喚魏延分付曰：「汝可引本部兵去桃花渡口下寨。如蠻兵渡水來敵，汝便棄了寨。望白旗處而走。限半個月內，須要連輸十五陣，棄七個寨柵。若輸了十四陣，也休來見我。」\\n魏延領命，心中不樂，怏怏而去。孔明又喚張翼另引一軍，依所指之處，築立寨柵去了。卻令張嶷、馬忠引本洞所降千人，如此行之各人都依計而行。\\n卻說孟獲與烏戈國主兀突骨曰：「諸葛亮多有巧計，只是埋伏。今後交戰，分付三軍：但見山谷之中，林木多處，不可輕進。」兀突骨曰：「大王說的有理。吾已知道中國人多行詭計。今後依此言行之。吾在前面廝殺，汝在背後教道。」\\n兩人商量已定。忽報蜀兵在桃花渡口北岸立起營寨。兀突骨即差二俘引藤甲軍渡河來，與蜀兵交戰。不數合，魏延敗走。蠻兵恐有埋伏，不趕自回。次日，魏延又去了營寨。蠻兵哨得，又引眾軍渡過河來戰。延出迎之。不數合，延敗走。蠻兵殺十餘里，見四下並無動靜，便在蜀寨中屯住。\\n次日，二俘長請兀突骨到寨，說知此事。兀突骨即引兵大進，將魏延追一陣。蜀兵皆棄甲拋戈而走。只見前有白旗，延引敗兵，急奔到白旗處，早有一寨，就寨中屯住。兀突骨驅兵追至，延引兵棄寨而走。蠻兵得了蜀寨。次日，又望前追殺。魏延回兵交戰，不三合又敗，只看白旗處而走。又有一寨，延就寨屯住。次日，蠻兵又至。延略戰又走。蠻兵占了蜀寨。\\n話休絮煩。魏延且戰且走，已敗十五陣，連棄七個營寨。蠻兵大進追殺。兀突骨自在軍前破敵，於路但見林木茂盛之處，便不敢進；卻使人遠望，果見樹陰之中，旌旗招颭。兀突骨謂孟獲曰：「果不出大王所料。」孟獲大笑曰：「諸葛亮今番被吾識破！大王連日勝了他十五陣，奪了七個營寨，蜀兵望風而走。諸葛亮已是計窮；只此一進，大事定矣！」\\n兀突骨大喜，遂不以蜀兵為念。至第十六日，魏延引敗殘兵而來，與藤甲軍對敵。兀突骨騎象當先，頭戴日月狼鬚帽；身披金珠瓔絡；兩肋下露出生鱗甲；眼目中微露光芒；手指魏延大罵。延撥馬便走。後面蠻兵大進。魏延引兵轉過了盤蛇谷，望白旗而走。兀突骨望見山上並無草木，料無埋伏，放心追殺。趕到谷中，見數十輛黑油櫃車在當路。蠻兵報曰：「此是蜀兵運糧道路，因大王兵至，撇下糧車而走。」\\n兀突骨大喜，催兵追趕，將出谷口，不見蜀兵。只見橫木亂石滾下，壘斷谷口。兀突骨令兵開路而進，忽見前面大小車輛，裝載乾柴，盡皆火起。兀突骨忙教退兵，只聞後軍發喊，報說谷口已被乾柴壘斷。車中原來是火藥，一齊燒著。\\n兀突骨見無草木，心尚不慌，令尋路而走。只見山上兩邊亂丟火把。火把到處，地中藥線皆看，就地飛起鐵炮。滿谷中火光亂舞。但逢藤甲，無有不著。將兀突骨并三萬藤甲軍，燒得互相擁抱，死於盤蛇谷中。\\n孔明在山上往下看時，只見蠻兵被火燒的伸拳舒腿，大半被鐵炮打的頭臉粉碎，皆死於谷中，臭不可聞。孔明垂淚而歎曰：「吾雖有功於社稷，必損壽矣！」左右將士，無不感。\\n卻說孟獲在寨中，正望蠻兵回報。忽然千餘人笑拜於寨前，言說：「烏戈國與蜀兵大戰，將諸葛亮圍在盤蛇谷中了。特請大王前去接應。我等皆是本洞之人，不得已而降蜀。今知大王前來，特來助戰。」\\n孟獲大喜，即引宗黨并所聚番人，連夜上馬；就令蠻兵引路。方到盤蛇谷時，只見火光甚烈，臭味難聞。獲知中計，急退兵時，左邊張嶷，右邊馬忠，兩路軍殺出。獲方欲抵敵，一聲喊起，蠻兵中大半皆是蜀兵，將蠻王宗黨并聚集的番人盡皆擒了。孟獲匹馬殺出重圍，望山徑而走。\\n正走之間，見山凹裏一簇人馬，擁出一輛小車，車中端坐一人，綸巾羽扇，身衣道袍，乃孔明也。孔明大喝曰：「反賊孟獲！今番如何！」獲急回馬走。傍邊閃過一將，攔住去路，乃是馬岱。孟獲措手不及，被馬岱活捉了。此時王平、張翼已引一軍，趕到蠻寨中，將祝融夫人并衣應老小皆活捉而來。\\n孔明歸到寨中，升帳而坐，謂眾將曰：「吾今此計，不得已而用之，大損陰德。我料敵人必算吾於林木多處埋伏，吾卻空設旌旗，實無兵馬，疑其心也。吾令魏文長連輸十五陣者，堅其心也。吾見盤蛇谷止一條路，兩壁皆是光石，並無樹木，下面都是沙石，因令馬岱將黑油車安排於谷中。車中油櫃內，皆是預先造下的火砲，名曰『地雷』。一砲中藏九砲，三十步埋之。中用竹竿通節，以引藥線；纔一發動，山殞石裂。\\n吾又令趙子龍預備草車，安排於谷口，又於山上準備大木亂石。卻令魏延賺兀突骨藤甲軍入谷，放出魏延，即斷其路，隨後焚之。吾聞：『利於水者必不利於火』藤甲雖刀箭不入，乃油浸之物，見火必著。蠻兵如此頑皮，非火攻安能取勝？使烏戈國之人不留種類者，是吾之大罪也！」\\n眾將拜伏曰：「丞相天機，神鬼莫測也！」孔明令押過孟獲來。孟獲跪於帳下。孔明令去其縛，教且在別帳與酒食官至坐榻前，如此如此，分付而去。\\n卻說孟獲與祝融夫人並孟優、帶來洞主、一切宗黨在別帳飲酒。忽一人入帳謂孟獲曰：「丞相面羞，不欲與公相見。特令我來放公回去，再招人馬來決勝負。公今可速去。」孟獲垂淚言曰：「七擒七縱，自古未嘗有也。吾雖化外之人，頗知禮義，直如此無羞恥乎？」遂同兄弟妻子宗黨等人，皆匍匐跪於帳下，肉袒謝罪曰：「丞相天威，南人不復反矣！」孔明曰：「公今服乎？」獲泣謝曰：「某子子孫孫皆感覆載生成之恩，安得不服？」\\n孔明乃請孟獲上帳，設宴慶賀，就令永為洞主。所奪之地，盡皆退還。孟獲宗黨及諸蠻兵，無不感戴，皆欣然跳躍而去。後人有詩讚孔明曰：\\n羽扇綸巾擁碧幛，七擒妙策制蠻王，至今溪洞傳威德，為選高原立廟堂。\\n長史費褘入諫曰：「今丞相親提士卒，深入不毛，收服蠻方；蠻王今已歸服，何不置官吏，與孟獲一同守之？」孔明曰：「如此有三不易：留外人則當留兵，兵無所食，一不易也；蠻人傷破，父兄死亡，留外人而不留兵，必成禍患，二不易也；蠻人累有廢殺之罪，自有嫌疑，留外人終不相信，三不易也。今吾不留人，不運糧，與相安於無事而已。」\\n眾人盡服。於是蠻方皆感孔明恩德，乃為孔明立生祠，四時享祀；皆呼之為「慈父」；各送珍珠金寶丹漆藥材，耕牛戰馬，以資軍用，誓不相反。南方已定。\\n卻說孔明犒軍已畢，班師回蜀，令魏延引本部兵為前鋒。延引兵方至瀘水，忽然陰雲四合，水面上一陣狂風驟起，飛沙走石，軍不能進。延退兵回報孔明。孔明遂請孟獲問之。正是：塞外蠻人方帖服，水邊鬼卒又猖狂。未知孟獲所言若何，且看下文分解。', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='bb319561-6a09-481f-a189-3e2ef6ba5958', embedding=None, metadata={'file_path': 'data/91-Romance-of-the-Three-Kingdoms.txt', 'file_name': '91-Romance-of-the-Three-Kingdoms.txt', 'file_type': 'text/plain', 'file_size': 16390, 'creation_date': '2025-01-16', 'last_modified_date': '2025-01-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='第九十一回：祭瀘水漢相班師，伐中原武侯上表\\n卻說孔明班師回國，孟獲率引大小洞主酋長，及諸部落羅拜相送；前軍至瀘水，時值九月秋天，忽然陰雲布合，狂風驟起；兵不能渡，回報孔明，孔明遂問孟獲。獲曰：「此水原有猖神作禍，往來者必須祭之。」孔明曰：「用何物享祭？」獲曰：「舊時國中因猖神作禍，用七七四十九顆人頭並黑牛白羊祭之，自然風恬浪靜，更兼連年豐稔。」孔明曰：「吾今事已平定，安可妄殺一人？」遂自到瀘水岸邊觀看。果見陰風大起，波濤洶湧，人馬皆驚。\\n孔明甚疑，即尋土人問之。土人告說：「自丞相經過之後，夜夜只聞得水邊鬼哭神號。自黃昏直至天曉，哭聲不絕。瘴煙之內，陰鬼無數。因此作禍，無人敢渡。孔明曰：「此乃我之罪愆也。前者馬岱引蜀兵千餘，皆死於水中；更兼殺死南人，皆棄於此；狂魂怨鬼，不能解釋，以致如此。吾今晚當親自往祭於水濱。」土人曰：「須依舊例，殺四十九顆人頭為祭，則怨鬼自散也。」孔明曰：「本為人死而成怨鬼，豈可又殺生人耶？吾自有主意。喚行廚宰殺牛馬，和麵為劑，塑成人頭，內以牛羊等肉代之，名曰「饅頭。」\\n當夜於瀘水岸上，設香案，鋪祭物，列燈四十九盞，揚旛招魂；將饅頭等物，陳設於地。三更時分，孔明金冠鶴氅，親自臨祭，令董厥讀祭文。其文曰：\\n維大漢建興三年秋九月一日，武鄉侯領益州牧丞相諸葛亮，謹陳祭儀，享於故歿王�n事蜀中將校以及南人亡者陰魂曰：「我大漢皇帝，威勝五霸，明繼三王。昨自遠方侵境，�n異俗起兵；縱蠆尾以興妖，恣狼心而逞亂。我奉王命，問罪遐荒；大舉貔貅，悉除螻蟻；雄�n軍雲集，狂寇冰消。纔聞破竹之聲，便是失猿之勢。但士卒兒郎，盡是九州豪傑；官僚將�n校，皆為四海英雄。習武從戎，投明事主，莫不同申三令，共展七擒；齊堅奉國之誠，共效�n忠君之志。何期汝等偶失兵機，緣落奸計；或為流矢所中，魂掩泉臺；或為刀劍所傷，魄�n歸長夜。生則有勇，死則成名。今凱歌欲還，獻俘將及。汝等英靈尚在，祈禱必聞。隨我旌�n旗，逐我部曲，同回上國，各認本鄉，受骨肉之蒸嘗，領家人之祭祀；莫作他鄉之鬼，徒為�n異域之魂。我當奏之天子，使汝等各家盡霑恩露；年給衣糧，月賜廩祿。用茲酬答，以慰汝心。至於本境土神，南方亡鬼，血食有常，憑依不遠。生者既凜天威，死者亦歸王化。想宜寧帖，毋致號啕。聊表丹誠，敬陳祭祀。嗚呼，哀哉！伏維尚饗！\\n讀祭文畢，孔明放聲大哭，極其痛切，情動三軍，無不下淚。孟獲等眾，盡皆哭泣。只見愁雲怨霧之中，隱隱有數千鬼魂，皆隨風而散。於是孔明令左右將祭物盡棄於瀘水之中。\\n次日孔明引大軍俱到瀘水南岸，但見雲散霧收，風靜浪平。蜀兵安然盡渡瀘水。果然鞭敲金鐙響，人唱凱歌還。行到永昌，孔明留王伉，呂凱守四郡；發付孟獲領眾自回，囑其勤政馭下，善撫居民，勿失農務。孟獲等涕泣拜別而去。\\n孔明自引大軍回成都。後主排鑾駕出郭三十里迎接，下輦立於道旁，以候孔明。孔明慌下車，伏道而言曰：「臣不能速平南方，使主上懷憂，臣之罪也。」後主扶起孔明，並車而回，設太平筵會，重賞三軍。自此遠邦進貢來朝者二百餘處。孔明奏准後主，將歿於王事者之家，一一優恤。人心懽悅，朝野清平。\\n卻說魏主曹丕在位七年，即蜀漢建興四年也。丕先納夫人甄氏，即袁紹次子袁熙之婦，前破鄴城時所得。後生一子，名叡，字元仲，自幼聰明，丕甚愛之。後丕又納安平廣宗人郭永之女為貴妃，甚有顏色﹔其父嘗曰：「吾女乃女中之王也。」故號為「女王」。自丕納為貴妃，因甄夫人失寵，郭貴妃欲謀為后，卻與幸臣張韜商議。時丕有疾，韜乃詐稱於甄夫人宮中掘得桐木偶人，上書天子年月日時，為壓鎮之事。丕大怒，遂將甄夫人賜死，立郭貴妃為皇后。因無出，養曹叡為己子。雖甚愛之，不立為嗣。\\n叡年至十五歲，弓馬熟嫻。當年春二月，丕帶叡出獵。行於山塢之間，趕出子母二鹿，丕一箭射倒母鹿，回視小鹿，馳於曹叡馬前。丕大呼曰：「吾兒何不射之？」叡在馬上泣告曰：「陛下已殺其母，安忍復殺其子？」丕聞之，擲弓於地曰：「吾兒真仁德之主也！」於是遂封叡為平原王。\\n夏五月，丕感寒疾，醫治不痊，乃召中軍大將軍曹真、鎮軍大將軍陳群、撫軍大將軍司馬懿三人入寢宮。丕喚曹叡至，指謂曹真等曰：「今朕病已沉重，不能復生。此子年幼，卿等三人，可善輔之，勿負朕心。」三人皆告曰：「陛下何出此言？臣等願竭力以事陛下，至千秋萬歲。」丕曰：「今年許昌城門無故自崩，乃不祥之兆，朕故自知必死也。」\\n正言間，內侍奏征東大將軍曹休入宮問安。丕召入謂曰：「卿等皆國家柱石之臣也，若能同心輔朕之子，朕死亦瞑目矣！」言訖，墮淚而薨。時年四十歲，在位七年。於是曹真、陳群、司馬懿、曹休等，一面舉哀，一面擁立曹叡為大魏皇帝。謚父丕為文皇帝，謚母甄氏為文昭皇后。封鐘繇為太傅，曹真為大將軍，曹休為大司馬，華歆為太尉，王朗為司徒，陳群為司空，司馬懿為驃騎大將軍。其餘文武官僚，各各封贈。大赦天下。時雍，涼，二州缺人守把，司馬懿上表乞守西涼等處。曹叡從之，遂封懿提督雍，涼等處兵馬。領詔去訖。\\n早有細作飛報入川。孔明大驚曰：「曹丕已死，孺子曹叡即位，餘皆不足慮，司馬懿深有謀略，今督雍、涼兵馬，倘訓練成時，深為蜀中之大患。不如先起兵伐之。」參軍馬謖曰：「今丞相平南方回，軍馬疲敝，只宜存恤，豈可復遠征？某有一計，使司馬懿自死於曹叡之手，未知丞相鈞意允否？」\\n孔明問是何計。馬謖曰：「司馬懿雖是魏國大臣，曹叡素懷疑忌。何不密遣人往洛陽、鄴郡等處，布散流言，道此人欲反？更作司馬懿告示天下榜文，遍貼諸處，使曹叡心疑，必然殺此人也。」孔明從之，即遣人密行此計去了。\\n卻說鄴城門上，忽一日見貼下告示一道。守門者揭了，來奏曹叡。叡觀之，其文曰：驃騎大將軍總領雍、涼等處兵馬事司馬懿，謹以信義布告天下：昔太祖武皇帝，創立基業，本欲立陳思王子建為社稷主﹔不幸奸讒交集，歲久潛龍。皇孫曹叡，素無德行，妄自居尊，有負太祖之遺意。今吾應天順人，（左克右寸）日興師，以慰萬民之望。告示到日，各宜歸命新君。如不順者，當滅九族！先此告聞，想宜知悉。\\n曹叡覽畢，大驚失色，急問群臣。太尉華歆奏曰：「司馬懿上表乞守雍、涼，正為此也。先時太祖武皇帝嘗謂臣曰：『司馬懿鷹視狼顧，不可付以兵權﹔久必為國家大禍。』今日反情已萌，可速誅之。」王朗奏曰：「司馬懿深明韜略，善曉兵機，素有大志﹔若不早除，久必為禍。」\\n叡乃降旨，欲興兵御駕親征。忽班部中閃出大將軍曹真奏曰：「不可。文皇帝托孤於臣等數人，是知司馬仲達無異志也。今事未知真假，遽爾加兵，乃逼之反耳。或者蜀、吳奸細行反間之計，使我君臣自亂，彼卻乘虛而擊，未可知也。陛下幸察之。」叡曰：「司馬懿若果謀反，將奈何？」真曰：「如陛下心疑，可仿漢高偽游雲夢之計。御駕幸安邑，司馬懿必然來迎﹔觀其動靜，就車前擒之，可也。」\\n叡從之，遂命曹真監國，親自領御林軍十萬，徑到安邑。司馬懿不知其故，欲令天子知其威嚴，乃整兵馬，率甲士數萬來迎。近臣奏曰：「司馬懿果率兵十餘萬，前來抗拒，實有反心矣。」叡慌命曹休先領兵迎之。司馬懿見兵馬前來，只疑車駕親至，伏道而迎。曹休出曰：「仲達受先帝托孤之重，何故反耶？」\\n懿大驚失色，汗流遍體，乃問其故。休備言前事。懿曰：「此吳、蜀奸細反間之計，欲使我君臣自相殘害，彼卻乘虛而來。某當自見天子辯之。」遂即退了兵馬，至叡車前俯伏泣奏曰：「臣受先帝托孤之重，安敢有異心？必是吳、蜀之奸計。臣請提一旅之師，先破蜀，後伐吳，報先帝與陛下，以明臣心。」叡疑慮未決。華歆奏曰：「不可付之兵權。可即罷歸田里。」叡依言。將司馬懿削職回鄉，命曹休總督雍、涼兵馬。曹叡駕回洛陽。\\n卻說細作探知此事，報入川中。孔明聞之大喜曰：「吾欲伐魏久矣，奈有司馬懿總雍、涼之兵。今既中計遭貶，吾有何憂？」次日，後主早朝，大會官僚，孔明出班上《出師表》一道。表曰：\\n臣亮言：先帝創業未半，而中道崩殂﹔今天下三分，益州罷敝，此誠危急存亡之秋也。然侍衛之臣，不懈於內﹔忠志之士，忘身於外者；蓋追先帝之殊遇，欲報之於陛下也。誠宜開張聖聽，以光先帝之遺德，恢宏志士之氣﹔不宜妄自菲薄，引喻失義，以塞忠諫之路也。宮中府中，俱為一體﹔陟罰臧否，不宜異同：若有作奸犯科，及為忠善者，宜付有司，論其刑賞，以昭陛下平明之治﹔不宜偏私，使內外異法也。侍中侍郎郭攸之、費褘、董允等，此皆良實，志慮忠純，是以先帝簡拔以遺陛。愚以為宮中之事，事無大小，悉以咨之，然後施行，必得裨補闕漏，有所廣益。將軍向寵，性行淑均，暢曉軍事，試用之於昔日，先帝稱之曰「能」，是以眾議舉寵以為督。愚以為營中之事，事無大小，悉以咨之，必能使行陣和穆，優劣得所也。親賢臣，遠小人，此先漢所以興隆也﹔親小人，遠賢臣，此後漢所以傾頹也。先帝在時，每與臣論此事，未嘗不歎息痛恨於桓靈也！侍中、尚書、長史、參軍，此悉貞亮死節之臣也。願陛下親之，信之，則漢室之隆，可計日而待也。臣本布衣，躬耕南陽，苟全性命於亂世，不求聞達於諸侯。先帝不以臣卑鄙，猥自枉屈，三顧臣於草廬之中，諮臣以當世之事，由是感激，遂許先帝以馳驅。後值傾覆，受任於敗軍之際，奉命於危難之間，爾來二十有一年矣。先帝知臣謹慎，故臨崩寄臣以大事也。受命以來，夙夜憂慮，恐付託不效，以傷先帝之明﹔故五月渡瀘，深入不毛。今南方已定，甲兵已足，當獎帥三軍，北定中原，庶竭駑鈍，攘除姦凶，興復漢室，還於舊都：此臣所以報先帝而忠陛下之職分也。至於斟酌損益，進盡忠言，則攸之、褘、允等之任也。願陛下託臣以討賊興復之效，不效則治臣之罪，以告先帝之靈﹔若無興復之言，則責攸之、褘、允等之咎，以彰其慢。陛下亦宜自謀，以諮諏善道，察納雅言，深追先帝遺詔。臣不勝受恩感激！今當遠離，臨表涕泣，不知所云。\\n後主覽表曰：「相父南征，遠涉艱難﹔方始回都，坐未安席﹔今又欲北伐，恐勞神思。」孔明曰：「臣受先帝託孤之重，夙夜未嘗有怠。今南方已平，可無內顧之憂﹔不就此時討賊，恢復中原，更待何日？”忽班部中太史譙周出奏曰：「臣夜觀天象，北方旺氣正盛，星曜倍明，未可圖也。」乃謂孔明曰：「丞相深明天文，又何故強為？」孔明曰：「天道變易不常，豈可拘執？吾今且駐兵馬於漢中，觀其動靜而後行。」\\n譙周苦諫不從。於是孔明乃留郭攸之、董允、費褘等為侍中，總攝宮中之事。又留向寵為大將，總督御林軍馬；陳震為侍中﹔蔣琬為參軍，張裔為長史，掌丞相府事﹔杜瓊為諫議大夫﹔杜微、楊洪為尚書﹔孟光、來敏，為祭酒﹔尹默、李譔為博士﹔郤正、費詩為秘書﹔譙周為太史。內外文武官僚一百餘員，同理蜀中之事。\\n孔明受詔歸府，喚諸將聽令。前督部鎮北將軍領丞相司馬、涼州刺史、都亭侯魏延，前軍都督領伏風太守張翼，牙門將裨將軍王平﹔後軍領兵使安漢將軍領建寧太守李恢，副將定遠將軍領漢中太守呂義，兼管運糧左軍領兵使平北將軍陳倉侯馬岱，副將飛衛將軍廖化，右軍領兵使奮威將軍博陽亭侯馬忠，鎮撫將軍關內侯張嶷，行中軍師車騎大將軍都鄉侯劉琰，中監軍揚武將軍鄧芝，中參軍安遠將軍馬謖，前將軍都亭侯袁琳，左將軍高陽侯吳懿，右將軍玄都侯高翔，後將軍安樂侯吳班，領長史綏軍將軍楊儀，前將軍征南將軍劉巴，前護軍偏將軍、漢成亭侯許允，左護軍篤信中郎將丁咸，右護軍偏將軍劉敏，後護軍典軍中郎將宮雝，行參軍昭武中郎將胡濟，行參軍諫議將軍閻晏，行參軍偏將軍爨習，行參軍稗將軍杜義，武略中郎將杜祺，綏軍都尉盛敦，從事武略中郎將樊岐，典軍書記樊建，丞相令史董厥，帳前左護衛使龍驤將軍關興，右護衛使虎翼將軍張苞。──以上一應官員，都隨著平北大都督丞相武鄉侯領益州牧知內外事諸葛亮。\\n分撥已定，又檄李嚴等守川口以拒東吳。選定建興五年春三月丙寅日，出師伐魏。忽帳下一老將，厲聲而進曰：「我雖年邁，尚有廉頗之勇，馬援之雄。此二古人皆不服老，何故不用我耶？」眾視之，乃趙雲也。孔明曰：「吾自平南回都，馬孟起病故，吾甚惜之，以為折一臂也。今將軍年紀已高，倘稍有參差，動搖一世英名，減卻蜀中銳氣。」雲厲聲曰：「吾自隨先帝以來，臨陣不退，遇敵則先，大丈夫得死於疆場者幸也，吾何恨焉，願為前部先鋒。」孔明再三苦勸不從。雲曰：「如不教我為先鋒，就撞死於階下！」孔明曰：「將軍既要為先鋒，須得一人同去。」\\n言未盡，一人應曰：「某雖不才，願助老將軍先引一軍前去破敵。」孔明視之，乃鄧芝也。孔明大喜，即撥精兵五千，副將十員，隨趙雲、鄧芝去訖。孔明出師，後主引百官送於北門外十里。孔明辭後主，旌旗蔽野，戈戟如林，率軍望漢中迤邐進發。\\n卻說邊庭探知此事，報入洛陽。是日曹叡設朝，近臣奏曰：「邊官報稱：諸葛亮率大兵三十餘萬，出屯漢中，令趙雲、鄧芝為前部先鋒，引兵入境。」叡大驚，問群臣曰：「誰可為將，以退蜀兵？」忽一人應聲而出曰：「臣父死於漢中，切齒之恨，未嘗得報。今蜀兵犯境，臣願引本部猛將，更乞陛下賜關西之兵，前往破蜀。上為國家效力，下報父讎，臣萬死不恨！」\\n眾視之，乃夏侯淵之子夏侯楙也。楙字子休﹔其性最急，又最吝。自幼嗣與夏侯惇為子。後夏侯淵為黃忠所斬，曹操憐之，以女清河公主招楙為駙馬，因此朝中欽敬。雖掌兵權，未嘗臨陣。當時自請出征，曹叡即命為大都督，調關西諸路軍馬前去破敵。\\n司徒王朗奏曰：「不可。夏侯駙馬素不曾經戰，今付以大任，非其所宜。更兼諸葛亮足智多謀，深通韜略，不可輕敵。」夏侯楙曰：「司徒莫非結連諸葛亮，欲為內應耶？吾自幼從父學習韜略，深通兵法，汝何欺我年幼？吾若不生擒諸葛亮，誓不回見天子！」\\n王朗等皆不敢言。夏侯楙辭了魏主，星夜到長安，調關西諸路軍馬二十餘萬，來敵孔明。正是：欲秉白旄麾將士，卻教黃吻掌兵權。未知勝負如何，且看下文分解。', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4df50dcb-edfe-4543-8315-67e035a47de1', embedding=None, metadata={'file_path': 'data/92-Romance-of-the-Three-Kingdoms.txt', 'file_name': '92-Romance-of-the-Three-Kingdoms.txt', 'file_type': 'text/plain', 'file_size': 14777, 'creation_date': '2025-01-16', 'last_modified_date': '2025-01-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='第九十二回：趙子龍力斬五將，諸葛亮智取三城\\n卻說孔明率兵前至沔縣，經過馬超墳墓，乃令其弟馬岱挂孝，孔明親自祭之。祭畢，回到寨中，商議進兵。忽哨馬報道：「魏主曹叡遣駙馬夏侯楙，調關中諸路軍馬，前來拒敵。」魏延上帳獻策曰：「夏侯楙乃膏粱子弟，懦弱無謀。延願得精兵五千，取路出褒中，循秦嶺以東，當子午谷而投北，不過十日，可到長安。夏侯楙若聞某驟至，必然棄城望邸閣橫門而走。某卻從東方而來，丞相可大驅士馬，自斜谷而進：如此行之，則咸陽以西，一舉可定也。」孔明笑曰：「此非萬全之計也：汝欺中原無好人物，倘有人進言，於山僻中以兵截殺，非惟五千人受害，亦大傷銳氣。決不可用。」魏延又曰：「丞相兵從大路進言，彼必盡起關中之兵，於路迎敵；則曠日持久，何時而得中原？」孔明曰：「吾從隴右居平坦大路，依法進兵，何憂不勝？」遂不用魏延之計。魏延怏怏不悅。孔明差人令趙雲進兵。\\n卻說夏侯楙在長安聚集諸路軍馬。時有西涼大將韓德，善使開山大斧，有萬夫不當之，勇，引西羌諸路兵八萬到來；見了夏侯楙，楙重賞之，就令為先鋒。德有四子，皆精通武藝，弓馬過人：長子韓瑛，次子韓瑤，三子韓瓊，四子韓琪。韓德帶四子并西羌兵八萬，取路至鳳鳴山，正遇蜀兵。兩陣對圓。韓德出馬，四子列於兩邊。德厲聲大罵曰：「反國之賊，安敢犯吾境界！」趙雲大怒，挺鎗縱馬，單搦韓德交戰。長子韓瑛，躍馬來迎；戰不三合，被趙雲一鎗刺死於馬下。次子韓瑤見之，縱馬揮刀來戰。趙雲施逞舊日虎威，抖擻精神迎戰。瑤抵敵不住。三子韓瓊，急挺方天戟驟馬前來夾攻。雲全然不懼，鎗法不亂。四子韓琪，見二兄戰雲不下，也縱馬掄兩口日月刀而來，圍住趙雲。雲在中央獨戰三將。少時，韓琪中鎗落馬。韓陣中偏將急出救去。雲拖鎗便走。韓瓊按戟，急取弓箭射之：連放三箭，皆被雲用鎗撥落。瓊大怒，仍綽方天戟縱馬趕來；卻被雲一箭射中面門，落馬而死。韓瑤縱馬舉寶刀便砍趙雲。雲棄鎗於地，閃過寶刀，生擒韓瑤歸陣，復縱馬取鎗殺過陣來。韓德見四子皆喪趙雲之手，肝膽皆裂，先走入陣去。西羌兵素知趙雲之名，今見其英勇如昔，誰敢交鋒；趙雲馬到處，陣陣倒退。趙雲匹馬單鎗，往來衝突，如入無人之境。後人有詩讚曰：憶昔常山趙子龍，年登七十建奇功。獨誅四將來衝陣，猶似當陽救主雄。\\n鄧芝見趙雲大勝，率蜀兵掩殺，西涼兵大敗而走。韓德險被趙雲擒住，棄甲步行而逃。￥雲與鄧芝收軍回寨。芝賀曰：「將軍壽已七旬，英勇如昨。今日陣前力斬四將，世所罕有！」雲曰：「丞相以吾年邁，不肯見用，故聊以自表耳。」遂差人解韓瑤，申報捷書，以達孔明。卻說韓德引敗軍回見夏侯楙，哭其事。楙自統兵來迎趙雲。探馬報入蜀寨，說夏侯楙引兵到。雲綽鎗上馬，引千餘軍，就鳳鳴山前擺成陣勢。當日夏侯楙戴金盔，坐白馬，手提大砍刀，立在門旗之下。見趙雲躍馬挺鎗，往來馳騁，楙欲自戰。韓德曰：「殺吾四子之讎，如何不報！」縱馬輪開山大斧，直取趙雲。雲奮怒挺鎗來迎；戰不三合，鎗起處，刺死韓德於馬下，急撥馬直取夏侯楙。楙慌忙閃入本陣。鄧芝驅兵掩殺，魏兵又折一陣，退十餘里下寨。楙連夜與眾將商議曰：「吾久聞趙雲之名，未嘗見面；今日年老，英雄尚在，方信當陽長（左土右反）之事。似此無人可敵，如之奈何？」參軍程武乃程昱之子也，進言曰：「某料趙雲有勇無謀，不足為慮。來日都督再引兵出，先伏兩軍於左右；都督臨陣先退，誘趙雲到伏兵處，都督卻登山指揮四面軍馬，重疊圍住，雲可擒矣。」楙從其言，遂遣董禧引三萬軍伏於左，薛則引三萬軍伏於右：二人埋伏已定。\\n次日，夏侯楙復整金鼓旗旛，率兵而進。趙雲、鄧芝出迎。芝在馬上謂趙雲曰：「昨夜魏兵大敗而走，今日復來，必有詐也，老將軍防之。」子龍曰：「量此乳臭小兒，何足道哉！吾今日必當擒之！」便躍馬而出，魏將潘遂出迎，戰不三合，撥馬便走。趙雲趕去，魏陣中八員將一齊來迎。放過夏侯楙先走，八將陸續奔走。趙雲乘勢追殺，鄧芝引兵繼進。趙雲深入重地，只聽得四面喊聲大震。鄧芝急收軍退回，左有董禧，右有薛則，兩路兵殺到。鄧芝兵少，不能解救。\\n趙雲被困在垓心，東衝西突，魏兵越厚。時雲手下止有千餘人，殺到山坡之下，只見夏侯楙在山上指揮三軍。趙雲投東則望東指，投西則望西指：因此趙雲不能突圍，乃引兵欲上山來。半山中擂木砲石打將下來，不能上山。趙雲從辰時殺至酉時，不能得走出，只得下馬少歇，且待月明再戰。卻纔卸甲而坐，月光方出，忽四下火光沖天，鼓聲大震，矢石如雨，魏兵殺到，皆叫曰：「趙雲早降！」雲急上馬迎敵、四面軍馬漸漸逼近，八方弩箭交射甚急，人馬皆不能向前。雲仰天歎曰：「吾不服老，死於此地矣！」忽東北角上喊聲大起，魏兵紛紛亂竄。\\n一彪軍殺到，為首大將持丈八點鋼矛，馬項下挂一顆人頭，雲視之，乃張苞也。苞見趙雲，言曰：「丞相恐老將軍有失，特遣某引軍五千兵接應。聞老將軍被困，故殺透重圍。正遇魏將薛則，被某殺之。」雲大喜，即與張苞殺出西北角來。只見魏兵棄戈奔走。一彪軍從外吶喊殺入，為首大將提偃月青龍刀，手挽人頭。雲視之，乃關興也。興曰：「奉丞相之命，恐老將軍有失，特引五千兵前來接應。卻纔陣上逢著魏將董禧，被吾一刀斬之，梟道在此。丞相隨後便到也。」雲曰：「二將軍已建奇功，不趁今日擒住夏侯楙，以定大事？」張苞聞言，遂引兵去了。興曰：「我也幹功去。」亦引兵去了。雲回顧左右曰：「他兩個是吾子姪輩，尚且爭先幹功；吾乃國家上將，朝廷舊臣，反不如此小輩耶？吾當捨老命以報先帝之恩！」於是引兵來捉夏侯楙。當夜三路兵夾攻，大破魏軍一陣。鄧芝引兵接應，殺得屍橫遍野，血流成河。夏侯楙乃無謀之人，更兼年幼，不曾經戰；見軍大亂，遂引帳下驍將百餘人，望南安郡而走。眾軍因見無主，盡皆逃竄。興、苞二將，聞夏侯楙望南安郡去了，連夜趕來。楙走入城中，緊閉城門，驅兵守禦。興、苞二人趕到，將城圍住；趙雲隨後也到：三面攻打。少時，鄧芝亦引兵到。一連圍了十日，攻打不下。忽報丞相留後軍住沔陽，左軍屯陽平，右軍屯石城，自引中軍來到。趙雲、鄧芝郡關興、張苞皆來拜問孔明，說連日攻城不下。孔明遂乘小車親到城邊周圍看了一遍，回寨升帳而坐。\\n眾將環立聽令。孔明曰：「此郡壕深成峻，不易攻也。吾正事不在此城，如汝等只久攻，倘魏兵分道而出，以取漢中，吾軍危矣。」鄧芝曰：「夏侯楙乃魏之駙馬，若擒此人，勝斬百將。今困於此，豈可棄之而去？」孔明曰：「吾自有計。此處西連天水郡，北抵安定郡；二處太守，不知何人？」探卒答曰：「天水太守馬遵，安定太守崔諒。」孔明大喜，乃喚魏延受計，如此如此；又喚關興、張苞受計，如此如此；又喚心腹軍士二人受計，如此行之。各將領命，引兵而去。孔明卻在南安城外，令軍運迆草堆於城下，口稱燒城。魏兵聞知，皆大笑不懼。\\n卻說安定太守崔諒，在城中聞蜀兵圍了南安，困住夏侯楙，十分慌懼，即點軍馬約共四千，守住城池。忽見一人自正南而來，口稱有機密事。崔諒喚入問之，答曰：「某是夏侯都督帳下心腹將裴緒，今奉都督將令，特來求救於天水、安定二郡。南安其急，每日城上縱火為號，專望二郡救兵，並不見到；因復差某殺出重圍，來此告急，可星夜起兵為外應。都督若見二郡兵到，卻開城門接應也。」諒曰：「有都督文書否？」緒貼肉取出，汗已濕透；略教一視，急令手下換了匹馬，便出城望天水而去。不二日，又報馬到，說天水太守已起兵救援南安去了，教安定接應。崔諒與府官商議。多官曰：「若不去救，失了南安，送了夏侯駙馬，皆我兩郡之罪也；只得救之。」諒即點起人馬，離城而去，只留文官守城。崔諒提兵向南安大進發，遙見火光沖天，催兵星夜前進。離南安尚有五十餘田，忽聞前後喊聲大雲，哨馬報道：「前面關興截住去路，背後張苞殺到！」安定之兵四下逃竄。諒大驚，乃領手下百餘人，往小路死戰得脫，奔回安定。方到城壕，城上亂箭射下來。蜀將魏延在城上叫曰：「吾已取了城也！何不早降？」\\n原來魏延扮作安定軍，夤夜賺開城門，蜀兵盡入：因此得了城池。崔諒慌投天水郡來。行不到一程，前面一彪軍擺開。大旗之下，一人綸巾羽扇，道袍鶴氅，端坐於車上。諒視之，乃孔明也，急撥回馬走。關興、張苞兩路兵追到，只叫：「早降！」崔諒見四面皆是蜀兵，不得已遂降，同歸大寨。孔明以上賓相待。孔明曰：「南安太守與足下交厚否？」諒曰：「此人乃楊阜之族弟楊陵也；與某鄰郡，交契甚厚。」孔明曰：「今欲煩足下入城，說楊陵擒夏侯楙，可乎？」諒曰：「丞相若令某去，可暫退軍馬，容某入城說之。」孔明從其言，即傳令，教四面軍馬各退二十里下寨。崔諒匹馬到城邊叫開城門，入到府中，與楊陵禮畢，細言其事。陵曰：「我等受魏主大恩，安忍背之？可將計就計而行。」遂引崔諒到夏侯楙處，備細說知。楙曰：「當用何計？」楊陵曰：「只推某獻城門，賺蜀兵入，卻就城中殺之。」\\n崔諒依計而行，出城見孔明，說：『楊陵獻城門，放大軍入城，以擒夏侯楙。陽陵本欲自捉，因手下勇士不多，未敢輕動。』孔明曰：「此事至易。今有足下原降兵百餘人，於內暗藏蜀將扮作安定軍馬，帶入城去，先伏於夏侯楙府下；卻暗約楊陵，待半夜之時，獻開城門，裏應外合。」崔諒暗思：「若不帶蜀將去，恐孔明生疑。且帶入去，就內先斬之，舉火為號，賺孔明入來殺之，可也。」因此應允。孔明囑曰：「吾遣親信關興、張苞隨足下先去，只推救軍殺入城中，以安定夏侯楙之心；但舉火，吾當親入城去擒之。」時值黃昏，關興、張苞受了孔明密計，披挂上馬，各執兵器，雜在安定軍中，隨崔諒來到南安城下。楊陵在城上撐起懸空板，倚定謢心欄，問曰：「何處軍馬？」崔諒曰：「安定救軍來到。」諒先射號箭上城，箭上帶著密書曰：「今諸葛亮先遣二將，伏於城中，要裏應外合，且不可驚動，恐泄漏計策。待入府中圖之。」楊陵將書見了夏侯楙，細言其事。楙曰：「既然諸葛亮中計，且教刀斧手百餘人，伏於府中。如二將隨崔太守到府下馬，閉門斬之；卻於城上舉火，賺諸葛亮入城。伏兵齊出，亮可擒矣。」\\n安排已畢，楊陵回到城上言曰：「既是安定軍馬，可放入城。」關興跟崔諒先行，張苞在後。楊陵下城，在門邊迎接。興手起刀落，斬楊陵於馬下。崔諒大驚，急撥馬走。到弔橋邊，張苞大喝曰：「賊子矢走！汝等詭計，如何瞞得丞相耶！」手起一鎗，刺崔諒於馬下。關興早到城上，舉起火來。四面蜀兵奔入。夏侯楙措手不及，開南門併力殺出。一彪軍攔住，為首大將，乃是王平；交馬只一合，生擒夏侯楙於馬上，餘皆殺死。\\n孔明入南安，招諭軍民，秋毫無犯。眾將各各獻功。孔明將夏侯楙囚於車中。鄧芝問曰：「丞相何故知崔諒詐也？」孔明曰：「吾已知此無降心，故意使入城。彼必盡情告與夏侯楙，欲將計就計而行。吾見來情，足知其詐，復使二將同去，以穩其心。此人若有真心，必然阻當；彼忻然同去者，恐吾疑也。他意中度二將同去，賺入城中殺之未遲；又令吾軍有託，放心而進。吾已暗囑二將，就城門下圖之。城內必無準備，吾軍隨後便去，此出其不意也。」眾將拜服。孔明曰：「賺崔諒者，吾使心腹人詐作魏將裴緒也。吾又去賺天水郡，至今未到，不知何故。今可乘勢取之。」乃留吳懿守南安，劉琰守安定，替出魏延軍馬去取天水郡。\\n卻說天水郡太守馬遵，聽知夏侯楙困在南安城中，乃聚文武百官商議。功曹梁緒、主簿尹賞、主記梁虔等曰：「夏侯駙馬乃金枝玉葉，倘有疏虞，難逃坐視之罪。太守何不盡起本部兵以救之？」馬遵正疑慮間，忽然夏侯駙馬差心腹裴緒到。緒入府，取公文付馬遵，說：「都督求安定、天水兩郡之兵，星夜救應。」言訖，匆匆而去。次日又有報馬到，稱說：「安定兵已先去了，教太守火急前來會合。」馬遵正欲起兵，忽一人自外而入曰：「太守中諸葛亮之計矣！」\\n眾視之，乃天水冀人也：姓姜名維，字伯約。父名冏，昔日曾為天水郡功曹，因羌人亂，沒於王事。維自幼博覽群書，兵法武藝，無所不通，奉母至孝，郡人敬之；後為中郎將，就參本部軍事。當日姜維謂馬遵曰：「近聞諸葛亮殺敗夏侯楙，困於南安，水泄不通，安得有人自重圍之中而出？又且裴緒乃無名下將。從不曾見；況安定報馬，又無公文：以此察之，此人乃蜀將詐稱魏將。賺得太守出城，料城中無備，必然暗伏一軍於左近，乘虛而取天水也。」馬遵大悟曰：「非伯約之言，則誤中奸計矣！」維笑曰：「太守放心：某有一計，可擒諸葛亮，解南安之危。」正是：運籌又遇強中手，鬥智還逢意外人。未知其計如何，且看下文分解。', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/90-Romance-of-the-Three-Kingdoms.txt\", \"./data/91-Romance-of-the-Three-Kingdoms.txt\", \"./data/92-Romance-of-the-Three-Kingdoms.txt\"]\n",
    ").load_data()\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphRAGExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from typing import Any, List, Callable, Optional, Union, Dict\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.core.async_utils import run_jobs\n",
    "from llama_index.core.indices.property_graph.utils import (\n",
    "    default_parse_triplets_fn,\n",
    ")\n",
    "from llama_index.core.graph_stores.types import (\n",
    "    EntityNode,\n",
    "    KG_NODES_KEY,\n",
    "    KG_RELATIONS_KEY,\n",
    "    Relation,\n",
    ")\n",
    "from llama_index.core.llms.llm import LLM\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.prompts.default_prompts import (\n",
    "    DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    ")\n",
    "from llama_index.core.schema import TransformComponent, BaseNode\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class GraphRAGExtractor(TransformComponent):\n",
    "    \"\"\"Extract triples from a graph.\n",
    "\n",
    "    Uses an LLM and a simple prompt + output parsing to extract paths (i.e. triples) and entity, relation descriptions from text.\n",
    "\n",
    "    Args:\n",
    "        llm (LLM):\n",
    "            The language model to use.\n",
    "        extract_prompt (Union[str, PromptTemplate]):\n",
    "            The prompt to use for extracting triples.\n",
    "        parse_fn (callable):\n",
    "            A function to parse the output of the language model.\n",
    "        num_workers (int):\n",
    "            The number of workers to use for parallel processing.\n",
    "        max_paths_per_chunk (int):\n",
    "            The maximum number of paths to extract per chunk.\n",
    "    \"\"\"\n",
    "\n",
    "    llm: LLM\n",
    "    extract_prompt: PromptTemplate\n",
    "    parse_fn: Callable\n",
    "    num_workers: int\n",
    "    max_paths_per_chunk: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: Optional[LLM] = None,\n",
    "        extract_prompt: Optional[Union[str, PromptTemplate]] = None,\n",
    "        parse_fn: Callable = default_parse_triplets_fn,\n",
    "        max_paths_per_chunk: int = 10,\n",
    "        num_workers: int = 4,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        from llama_index.core import Settings\n",
    "\n",
    "        if isinstance(extract_prompt, str):\n",
    "            extract_prompt = PromptTemplate(extract_prompt)\n",
    "            # extract_prompt = (\n",
    "            #     \"Some text is provided below. Given the text, extract up to \"\n",
    "            #     \"{max_knowledge_triplets} \"\n",
    "            #     \"knowledge triplets in the form of (subject, predicate, object). Avoid stopwords and use Traditional Chinese.\\n\"\n",
    "            #     \"---------------------\\n\"\n",
    "            #     \"Example:\"\n",
    "            #     \"Text: 小美是小明的媽媽\"\n",
    "            #     \"Triplets:\\n(小美, 是母親, 小明)\\n\"\n",
    "            #     \"Text: 曹操在官渡之戰中擊敗了袁紹。\"\n",
    "            #     \"Triplets:\"\n",
    "            #     \"(曹操, 參與, 官渡之戰)\"\n",
    "            #     \"(曹操, 擊敗了, 袁紹)\"\n",
    "\n",
    "            #     \"---------------------\\n\"\n",
    "            #     \"Text: {text}\\n\"\n",
    "            #     \"Triplets:\\n\"\n",
    "            # )\n",
    "\n",
    "        super().__init__(\n",
    "            llm=llm or Settings.llm,\n",
    "            extract_prompt=extract_prompt or DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    "            parse_fn=parse_fn,\n",
    "            num_workers=num_workers,\n",
    "            max_paths_per_chunk=max_paths_per_chunk,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def class_name(cls) -> str:\n",
    "        return \"GraphExtractor\"\n",
    "\n",
    "    def __call__(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes.\"\"\"\n",
    "        return asyncio.run(\n",
    "            self.acall(nodes, show_progress=show_progress, **kwargs)\n",
    "        )\n",
    "\n",
    "    async def _aextract(self, node: BaseNode) -> BaseNode:\n",
    "        \"\"\"Extract triples from a node.\"\"\"\n",
    "        assert hasattr(node, \"text\")\n",
    "\n",
    "        text = node.get_content(metadata_mode=\"llm\")\n",
    "        try:\n",
    "            llm_response = await self.llm.apredict(\n",
    "                self.extract_prompt,\n",
    "                text=text,\n",
    "                max_knowledge_triplets=self.max_paths_per_chunk,\n",
    "            )\n",
    "            entities, entities_relationship = self.parse_fn(llm_response)\n",
    "        except ValueError:\n",
    "            entities = []\n",
    "            entities_relationship = []\n",
    "\n",
    "        existing_nodes = node.metadata.pop(KG_NODES_KEY, [])\n",
    "        existing_relations = node.metadata.pop(KG_RELATIONS_KEY, [])\n",
    "        entity_metadata = node.metadata.copy()\n",
    "        for entity, entity_type, description in entities:\n",
    "            entity_metadata[\"entity_description\"] = description\n",
    "            entity_node = EntityNode(\n",
    "                name=entity, label=entity_type, properties=entity_metadata\n",
    "            )\n",
    "            existing_nodes.append(entity_node)\n",
    "\n",
    "        relation_metadata = node.metadata.copy()\n",
    "        for triple in entities_relationship:\n",
    "            subj, obj, rel, description = triple\n",
    "            relation_metadata[\"relationship_description\"] = description\n",
    "            rel_node = Relation(\n",
    "                label=rel,\n",
    "                source_id=subj,\n",
    "                target_id=obj,\n",
    "                properties=relation_metadata,\n",
    "            )\n",
    "\n",
    "            existing_relations.append(rel_node)\n",
    "\n",
    "        node.metadata[KG_NODES_KEY] = existing_nodes\n",
    "        node.metadata[KG_RELATIONS_KEY] = existing_relations\n",
    "        return node\n",
    "\n",
    "    async def acall(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes async.\"\"\"\n",
    "        jobs = []\n",
    "        for node in nodes:\n",
    "            jobs.append(self._aextract(node))\n",
    "\n",
    "        return await run_jobs(\n",
    "            jobs,\n",
    "            workers=self.num_workers,\n",
    "            show_progress=show_progress,\n",
    "            desc=\"Extracting paths from text\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphRAGStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "from graspologic.partition import hierarchical_leiden\n",
    "from collections import defaultdict\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "\n",
    "class GraphRAGStore(Neo4jPropertyGraphStore):\n",
    "    community_summary = {}\n",
    "    entity_info = None\n",
    "    max_cluster_size = 5\n",
    "\n",
    "    def __init__(self, username, password, url):\n",
    "        super().__init__(username=username, password=password, url=url)\n",
    "\n",
    "    def generate_community_summary(self, text):\n",
    "        \"\"\"Generate summary for a given text using an LLM.\"\"\"\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=(\n",
    "                    \"You are provided with a set of relationships from a knowledge graph, each represented as \"\n",
    "                    \"entity1->entity2->relation->relationship_description. Your task is to create a summary of these \"\n",
    "                    \"relationships. The summary should include the names of the entities involved and a concise synthesis \"\n",
    "                    \"of the relationship descriptions. The goal is to capture the most critical and relevant details that \"\n",
    "                    \"highlight the nature and significance of each relationship. Ensure that the summary is coherent and \"\n",
    "                    \"integrates the information in a way that emphasizes the key aspects of the relationships.You must using Traditional Chinese.\"\n",
    "                ),\n",
    "            ),\n",
    "            ChatMessage(role=\"user\", content=text),\n",
    "        ]\n",
    "        response = gpt4o.chat(messages)\n",
    "        clean_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return clean_response\n",
    "\n",
    "    def build_communities(self):\n",
    "        \"\"\"Builds communities from the graph and summarizes them.\"\"\"\n",
    "        nx_graph = self._create_nx_graph()\n",
    "        community_hierarchical_clusters = hierarchical_leiden(\n",
    "            nx_graph, max_cluster_size=self.max_cluster_size\n",
    "        )\n",
    "        self.entity_info, community_info = self._collect_community_info(\n",
    "            nx_graph, community_hierarchical_clusters\n",
    "        )\n",
    "        self._summarize_communities(community_info)\n",
    "\n",
    "    def _create_nx_graph(self):\n",
    "        \"\"\"Converts internal graph representation to NetworkX graph.\"\"\"\n",
    "        nx_graph = nx.Graph()\n",
    "        triplets = self.get_triplets()\n",
    "        for entity1, relation, entity2 in triplets:\n",
    "            nx_graph.add_node(entity1.name)\n",
    "            nx_graph.add_node(entity2.name)\n",
    "            nx_graph.add_edge(\n",
    "                relation.source_id,\n",
    "                relation.target_id,\n",
    "                relationship=relation.label,\n",
    "                description=relation.properties[\"relationship_description\"],\n",
    "            )\n",
    "        return nx_graph\n",
    "\n",
    "    def _collect_community_info(self, nx_graph, clusters):\n",
    "        \"\"\"\n",
    "        Collect information for each node based on their community,\n",
    "        allowing entities to belong to multiple clusters.\n",
    "        \"\"\"\n",
    "        entity_info = defaultdict(set)\n",
    "        community_info = defaultdict(list)\n",
    "\n",
    "        for item in clusters:\n",
    "            node = item.node\n",
    "            cluster_id = item.cluster\n",
    "\n",
    "            # Update entity_info\n",
    "            entity_info[node].add(cluster_id)\n",
    "\n",
    "            for neighbor in nx_graph.neighbors(node):\n",
    "                edge_data = nx_graph.get_edge_data(node, neighbor)\n",
    "                if edge_data:\n",
    "                    detail = f\"{node} -> {neighbor} -> {edge_data['relationship']} -> {edge_data['description']}\"\n",
    "                    community_info[cluster_id].append(detail)\n",
    "\n",
    "        # Convert sets to lists for easier serialization if needed\n",
    "        entity_info = {k: list(v) for k, v in entity_info.items()}\n",
    "\n",
    "        return dict(entity_info), dict(community_info)\n",
    "\n",
    "    def _summarize_communities(self, community_info):\n",
    "        \"\"\"Generate and store summaries for each community.\"\"\"\n",
    "        for community_id, details in community_info.items():\n",
    "            details_text = (\n",
    "                \"\\n\".join(details) + \".\"\n",
    "            )  # Ensure it ends with a period\n",
    "            self.community_summary[\n",
    "                community_id\n",
    "            ] = self.generate_community_summary(details_text)\n",
    "\n",
    "    def get_community_summaries(self):\n",
    "        \"\"\"Returns the community summaries, building them if not already done.\"\"\"\n",
    "        if not self.community_summary:\n",
    "            self.build_communities()\n",
    "        return self.community_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphRAGQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.llms import LLM\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "class GraphRAGQueryEngine(CustomQueryEngine):\n",
    "    graph_store: GraphRAGStore\n",
    "    index: PropertyGraphIndex\n",
    "    llm: LLM\n",
    "    similarity_top_k: int = 20\n",
    "\n",
    "    def custom_query(self, query_str: str) -> str:\n",
    "        \"\"\"Process all community summaries to generate answers to a specific query.\"\"\"\n",
    "\n",
    "        entities = self.get_entities(query_str, self.similarity_top_k)\n",
    "\n",
    "        community_ids = self.retrieve_entity_communities(\n",
    "            self.graph_store.entity_info, entities\n",
    "        )\n",
    "        community_summaries = self.graph_store.get_community_summaries()\n",
    "        community_answers = [\n",
    "            self.generate_answer_from_summary(community_summary, query_str)\n",
    "            for id, community_summary in community_summaries.items()\n",
    "            if id in community_ids\n",
    "        ]\n",
    "\n",
    "        final_answer = self.aggregate_answers(community_answers)\n",
    "        return final_answer\n",
    "\n",
    "    def get_entities(self, query_str, similarity_top_k):\n",
    "        nodes_retrieved = self.index.as_retriever(\n",
    "            similarity_top_k=similarity_top_k\n",
    "        ).retrieve(query_str)\n",
    "\n",
    "        enitites = set()\n",
    "        pattern = (\n",
    "            r\"^(\\w+(?:\\s+\\w+)*)\\s*->\\s*([a-zA-Z\\s]+?)\\s*->\\s*(\\w+(?:\\s+\\w+)*)$\"\n",
    "        )\n",
    "\n",
    "        for node in nodes_retrieved:\n",
    "            matches = re.findall(\n",
    "                pattern, node.text, re.MULTILINE | re.IGNORECASE\n",
    "            )\n",
    "\n",
    "            for match in matches:\n",
    "                subject = match[0]\n",
    "                obj = match[2]\n",
    "                enitites.add(subject)\n",
    "                enitites.add(obj)\n",
    "\n",
    "        return list(enitites)\n",
    "\n",
    "    def retrieve_entity_communities(self, entity_info, entities):\n",
    "        \"\"\"\n",
    "        Retrieve cluster information for given entities, allowing for multiple clusters per entity.\n",
    "\n",
    "        Args:\n",
    "        entity_info (dict): Dictionary mapping entities to their cluster IDs (list).\n",
    "        entities (list): List of entity names to retrieve information for.\n",
    "\n",
    "        Returns:\n",
    "        List of community or cluster IDs to which an entity belongs.\n",
    "        \"\"\"\n",
    "        community_ids = []\n",
    "\n",
    "        for entity in entities:\n",
    "            if entity in entity_info:\n",
    "                community_ids.extend(entity_info[entity])\n",
    "\n",
    "        return list(set(community_ids))\n",
    "\n",
    "    def generate_answer_from_summary(self, community_summary, query):\n",
    "        \"\"\"Generate an answer from a community summary based on a given query using LLM.\"\"\"\n",
    "        prompt = (\n",
    "            f\"Given the community summary: {community_summary}, \"\n",
    "            f\"how would you answer the following query? Answer in Traditional Chinese. Query: {query}\"\n",
    "        )\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=\"I need an answer based on the above information.\",\n",
    "            ),\n",
    "        ]\n",
    "        response = self.llm.chat(messages)\n",
    "        cleaned_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return cleaned_response\n",
    "\n",
    "    def aggregate_answers(self, community_answers):\n",
    "        \"\"\"Aggregate individual community answers into a final, coherent response.\"\"\"\n",
    "        # intermediate_text = \" \".join(community_answers)\n",
    "        prompt = \"Combine the following intermediate answers into a final, concise response and answer in Traditional Chinese.\"\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=f\"Intermediate answers: {community_answers}\",\n",
    "            ),\n",
    "        ]\n",
    "        final_response = self.llm.chat(messages)\n",
    "        cleaned_final_response = re.sub(\n",
    "            r\"^assistant:\\s*\", \"\", str(final_response)\n",
    "        ).strip()\n",
    "        return cleaned_final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build End to End GraphRAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=250,\n",
    "    chunk_overlap=24,\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ProperGraphIndex using GraphRAGExtractor and GraphRAGStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "KG_TRIPLET_EXTRACT_TMPL = \"\"\"\n",
    "-Goal-\n",
    "Given a text document, identify all entities and their entity types from the text and all relationships among the identified entities.\n",
    "Given the text, extract up to {max_knowledge_triplets} entity-relation triplets.\n",
    "\n",
    "-Steps-\n",
    "1. Identify all entities. For each identified entity, extract the following information:\n",
    "- entity_name: Name of the entity, use Traditional Chinese only.\n",
    "- entity_type: Type of the entity\n",
    "- entity_description: Comprehensive description of the entity's attributes and activities, use Traditional Chinese only.\n",
    "Format each entity as (\"entity\"$$$$\"\"$$$$\"\"$$$$\"\")\n",
    "\n",
    "2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\n",
    "For each pair of related entities, extract the following information:\n",
    "- source_entity: name of the source entity, as identified in step 1\n",
    "- target_entity: name of the target entity, as identified in step 1\n",
    "- relation: relationship between source_entity and target_entity\n",
    "- relationship_description: explanation as to why you think the source entity and the target entity are related to each other, use Traditional Chinese only.\n",
    "\n",
    "Format each relationship as (\"relationship\"$$$$\"\"$$$$\"\"$$$$\"\"$$$$\"\")\n",
    "\n",
    "3. When finished, output.\n",
    "\n",
    "-Real Data-\n",
    "######################\n",
    "text: {text}\n",
    "######################\n",
    "output:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_pattern = r'\\(\"entity\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\)'\n",
    "relationship_pattern = r'\\(\"relationship\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\)'\n",
    "\n",
    "\n",
    "def parse_fn(response_str: str) -> Any:\n",
    "    entities = re.findall(entity_pattern, response_str)\n",
    "    relationships = re.findall(relationship_pattern, response_str)\n",
    "    return entities, relationships\n",
    "\n",
    "\n",
    "kg_extractor = GraphRAGExtractor(\n",
    "    llm=gpt4o,\n",
    "    extract_prompt=KG_TRIPLET_EXTRACT_TMPL,\n",
    "    max_paths_per_chunk=2,\n",
    "    parse_fn=parse_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text: 100%|██████████| 134/134 [03:37<00:00,  1.63s/it]\n",
      "Generating embeddings: 100%|██████████| 14/14 [00:01<00:00, 12.98it/s]\n",
      "Generating embeddings: 100%|██████████| 71/71 [01:01<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "graph_store = GraphRAGStore(\n",
    "    username=os.environ[\"LI_NEO4J_USERNAME\"],\n",
    "    password=os.environ[\"LI_NEO4J_PASSWORD\"],\n",
    "    url=os.environ[\"LI_NEO4J_URI\"],\n",
    ")\n",
    "\n",
    "index = PropertyGraphIndex(\n",
    "    nodes=nodes,\n",
    "    kg_extractors=[kg_extractor],\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EntityNode(label='人物', embedding=None, properties={'creation_date': '2025-01-16', 'id': '孔明', 'last_modified_date': '2025-01-16', 'entity_description': '孔明，即諸葛亮，是蜀國的丞相，智謀過人，指揮南安之戰並成功俘虜夏侯楙。\"$$$$\"', 'file_size': 14777, 'file_path': 'data/92-Romance-of-the-Three-Kingdoms.txt', 'file_name': '92-Romance-of-the-Three-Kingdoms.txt', 'triplet_source_id': '9098c4c4-b91e-405d-9267-bf9454eb6b1b', 'file_type': 'text/plain'}, name='孔明'),\n",
       " Relation(label='使用', source_id='孔明', target_id='紅油櫃車', properties={'creation_date': '2025-01-16', 'last_modified_date': '2025-01-16', 'file_size': 20175, 'file_path': 'data/90-Romance-of-the-Three-Kingdoms.txt', 'file_name': '90-Romance-of-the-Three-Kingdoms.txt', 'relationship_description': '孔明命令左右取了十輛紅油櫃車到帳下，顯示他在軍事行動中使用這些車輛。\"$$$$\"', 'triplet_source_id': 'a06922b1-0519-4632-865b-48356702668f', 'file_type': 'text/plain'}),\n",
       " EntityNode(label='物品', embedding=None, properties={'creation_date': '2025-01-16', 'id': '紅油櫃車', 'last_modified_date': '2025-01-16', 'entity_description': '紅油櫃車是一種車輛，車身塗有紅色油漆，用於軍事用途。\"$$$$\"', 'file_size': 20175, 'file_path': 'data/90-Romance-of-the-Three-Kingdoms.txt', 'file_name': '90-Romance-of-the-Three-Kingdoms.txt', 'triplet_source_id': 'a06922b1-0519-4632-865b-48356702668f', 'file_type': 'text/plain'}, name='紅油櫃車')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'creation_date': '2025-01-16',\n",
       " 'last_modified_date': '2025-01-16',\n",
       " 'file_size': 20175,\n",
       " 'file_path': 'data/90-Romance-of-the-Three-Kingdoms.txt',\n",
       " 'file_name': '90-Romance-of-the-Three-Kingdoms.txt',\n",
       " 'relationship_description': '孔明命令左右取了十輛紅油櫃車到帳下，顯示他在軍事行動中使用這些車輛。\"$$$$\"',\n",
       " 'triplet_source_id': 'a06922b1-0519-4632-865b-48356702668f',\n",
       " 'file_type': 'text/plain'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()[10][1].properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproperty_graph_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_communities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m, in \u001b[0;36mGraphRAGStore.build_communities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m community_hierarchical_clusters \u001b[38;5;241m=\u001b[39m hierarchical_leiden(\n\u001b[1;32m     42\u001b[0m     nx_graph, max_cluster_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_cluster_size\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentity_info, community_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collect_community_info(\n\u001b[1;32m     45\u001b[0m     nx_graph, community_hierarchical_clusters\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_summarize_communities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommunity_info\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 98\u001b[0m, in \u001b[0;36mGraphRAGStore._summarize_communities\u001b[0;34m(self, community_info)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m community_id, details \u001b[38;5;129;01min\u001b[39;00m community_info\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     93\u001b[0m     details_text \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(details) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     )  \u001b[38;5;66;03m# Ensure it ends with a period\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommunity_summary[\n\u001b[1;32m     97\u001b[0m         community_id\n\u001b[0;32m---> 98\u001b[0m     ] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_community_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetails_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m, in \u001b[0;36mGraphRAGStore.generate_community_summary\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate summary for a given text using an LLM.\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     21\u001b[0m     ChatMessage(\n\u001b[1;32m     22\u001b[0m         role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     ChatMessage(role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, content\u001b[38;5;241m=\u001b[39mtext),\n\u001b[1;32m     33\u001b[0m ]\n\u001b[0;32m---> 34\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgpt4o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m clean_response \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^assistant:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(response))\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_response\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/llama_index/core/llms/callbacks.py:173\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    165\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    166\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m     },\n\u001b[1;32m    171\u001b[0m )\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    175\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[1;32m    176\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    177\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[1;32m    178\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[1;32m    179\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/llama_index/llms/openai/base.py:355\u001b[0m, in \u001b[0;36mOpenAI.chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     chat_fn \u001b[38;5;241m=\u001b[39m completion_to_chat_decorator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_complete)\n\u001b[0;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchat_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/llama_index/llms/openai/base.py:106\u001b[0m, in \u001b[0;36mllm_retry_decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     99\u001b[0m retry \u001b[38;5;241m=\u001b[39m create_retry_decorator(\n\u001b[1;32m    100\u001b[0m     max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m    101\u001b[0m     random_exponential\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m     max_seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m    105\u001b[0m )\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/tenacity/__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/llama_index/llms/openai/base.py:432\u001b[0m, in \u001b[0;36mOpenAI._chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m to_openai_message_dicts(\n\u001b[1;32m    427\u001b[0m     messages,\n\u001b[1;32m    428\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    429\u001b[0m )\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreuse_client:\n\u001b[0;32m--> 432\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m client:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/openai/resources/chat/completions.py:859\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    856\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    857\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    858\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llamaindex/lib/python3.10/site-packages/openai/_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1073\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}"
     ]
    }
   ],
   "source": [
    "index.property_graph_store.build_communities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create QueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = GraphRAGQueryEngine(\n",
    "    graph_store=index.property_graph_store,\n",
    "    llm=gpt4o,\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"孔明和孟獲之間發生過什麼事？\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"孔明和孟獲之間發生過什麼事？\")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGAS 自動生成目前有問題\n",
    "\n",
    "https://github.com/explodinggradients/ragas/issues/1730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ragas.testset import TestsetGenerator\n",
    "\n",
    "# generator = TestsetGenerator.from_llama_index(\n",
    "#     llm=gpt4o,\n",
    "#     embedding_model=embed_model,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate testset\n",
    "# testset = generator.generate_with_llamaindex_docs(\n",
    "#     documents,\n",
    "#     testset_size=5,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No-LLM Evaluation Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "sample_queries = [\n",
    "    \"誰是祝融夫人？\",\n",
    "    \"孟獲被諸葛亮第幾次擒住後才真心歸降？\",\n",
    "    \"孔明用什麼方法平定了烏戈國的藤甲軍？\",\n",
    "    \"趙雲在鳳鳴山與韓德及其四子交戰的結果如何？\",\n",
    "    \"孔明如何智取南安城？\",\n",
    "]\n",
    "\n",
    "expected_responses = [\n",
    "    \"祝融夫人是孟獲的妻子，南蠻祝融氏之後，善使飛刀，百發百中。\",\n",
    "    \"孟獲被諸葛亮第七次擒住後才真心歸降，並誓不再反。\",\n",
    "    \"孔明利用火攻之計，在盤蛇谷用火藥和火砲燒毀了烏戈國的藤甲軍。\",\n",
    "    \"趙雲在鳳鳴山與韓德及其四子交戰，最終斬殺了韓德及其三子，並生擒了次子韓瑤。\",\n",
    "    \"孔明利用崔諒和楊陵的內應計策，讓關興和張苞扮作安定軍馬進入南安城，最終擒住了夏侯楙。\",\n",
    "]\n",
    "\n",
    "dataset = []\n",
    "\n",
    "# for query, reference in zip(sample_queries, expected_responses):\n",
    "#     relevant_docs = vector_retriever.invoke(query)\n",
    "#     response = KG_chain.invoke(input=query)\n",
    "#     dataset.append(\n",
    "#         {\n",
    "#             \"user_input\": query,\n",
    "#             \"retrieved_contexts\": [rdoc.page_content for rdoc in relevant_docs],\n",
    "#             \"response\": response,\n",
    "#             \"reference\": reference,\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "# evaluation_dataset = EvaluationDataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ragas import evaluate\n",
    "# from ragas.llms import LangchainLLMWrapper\n",
    "# from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "\n",
    "# evaluator_llm = LangchainLLMWrapper(gpt4o)\n",
    "\n",
    "# result = evaluate(\n",
    "#     dataset=evaluation_dataset,\n",
    "#     metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],\n",
    "#     llm=evaluator_llm,\n",
    "# )\n",
    "\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the `QueryEngine` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import metrics\n",
    "# from ragas.metrics import (\n",
    "#     Faithfulness,\n",
    "#     AnswerRelevancy,\n",
    "#     ContextPrecision,\n",
    "#     ContextRecall,\n",
    "# )\n",
    "\n",
    "# # init metrics with evaluator LLM\n",
    "# from ragas.llms import LlamaIndexLLMWrapper\n",
    "\n",
    "# evaluator_llm = LlamaIndexLLMWrapper(gpt4o)\n",
    "# metrics = [\n",
    "#     Faithfulness(llm=evaluator_llm),\n",
    "#     AnswerRelevancy(llm=evaluator_llm),\n",
    "#     ContextPrecision(llm=evaluator_llm),\n",
    "#     ContextRecall(llm=evaluator_llm),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert to Ragas Evaluation Dataset\n",
    "# ragas_dataset = testset.to_evaluation_dataset()\n",
    "# ragas_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ragas.integrations.llama_index import evaluate\n",
    "\n",
    "# result = evaluate(\n",
    "#     query_engine=query_engine,\n",
    "#     metrics=metrics,\n",
    "#     dataset=ragas_dataset,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # final scores\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
