{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdE0k3jAS_AG"
      },
      "source": [
        "# Week 2: RAG\n",
        "\n",
        "Two methods to equip a model with new knowledge:\n",
        "1. **RAG (Retrieval-Augmented Generation)**\n",
        "2. Fine-tuning\n",
        "\n",
        "---\n",
        "\n",
        "In this tutorial, we will:  \n",
        "1. Demonstrate the limitations of LLMs with examples.\n",
        "2. Build a RAG using LangChain and LangGraph.\n",
        "3. Enable the LLM's web search functionality.  \n",
        "\n",
        "## RAG workflow\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*8_4t5Rno_9lQaMpmR33g7g.jpeg\">\n",
        "\n",
        "## Table of Contents:\n",
        "\n",
        "- [Install dependencies](#install-dependencies)\n",
        "- [Setup Google Gemini API Key](#setup-google-gemini-api-key)\n",
        "    - [Register](#register)\n",
        "    - [Enter your API Key for this Colab](#enter-your-api-key-for-this-colab)\n",
        "    - [The LLM Model we're going to use](#the-llm-model-were-going-to-use)\n",
        "- [Limitations of Language Models](#limitations-of-language-models)\n",
        "    - [Hallucinations](#hallucinations)\n",
        "        - [Let's try in legal fields](#lets-try-in-legal-fields)\n",
        "    - [Knowledge cut-off](#knowledge-cut-off)\n",
        "        - [LLMs won't know about things that happened recently](#llms-wont-know-about-things-that-happened-recently)\n",
        "- [Let's build RAG to solve it!](#lets-build-rag-to-solve-it)\n",
        "    - [The Knowledge we want LLM to know](#the-knowledge-we-want-llm-to-know)\n",
        "    - [Web Scraping these Knowledge](#web-scraping-these-knowledge)\n",
        "    - [Splitting and Chunking Data](#splitting-and-chunking-data)\n",
        "    - [Setup Embedding Model](#setup-embedding-model)\n",
        "    - [Vector Database](#vector-database)\n",
        "    - [Save embedding into Vector DB](#save-embedding-into-vector-db)\n",
        "    - [Define Prompt](#define-prompt)\n",
        "    - [Building RAG Workflow](#building-rag-workflow)\n",
        "    - [Done! Let's try it!](#done-lets-try-it)\n",
        "        - [Some question you can try](#some-question-you-can-try)\n",
        "        - [Trying harder question](#trying-harder-question)\n",
        "- [RAG Use Case Overview](#rag-use-case-overview)\n",
        "- [Enable Web Search Functionalities](#enable-web-search-functionalities)\n",
        "  - [Gemini Now Performs Web Searches Before Answering](#gemini-now-performs-web-searches-before-answering)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "q9JZiQ5civkY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "apzcASxjVepb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install langchain langchain-google-genai\n",
        "!pip install langchain-text-splitters langchain-community langgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Google Gemini API Key"
      ],
      "metadata": {
        "id": "cDQUV0ullgt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register"
      ],
      "metadata": {
        "id": "x8wvGOON-1qE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UTlv3PUTWz2"
      },
      "source": [
        "1. Visit the website: [https://aistudio.google.com/](https://aistudio.google.com/) and log in with your Google account.\n",
        "\n",
        "2. Click on \"Get API key.\"\n",
        "\n",
        "<img src=\"https://lh3.google.com/u/0/d/16x6gM2WAvmbOkayzKGtfnavNPFp3Pgz4\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_LrxeOVYrD7"
      },
      "source": [
        "3. Agree to the terms of use by selecting only the first checkbox.\n",
        "\n",
        "<img src=\"https://lh3.google.com/u/0/d/1bN1iR64XS-ibE-L47Dy_nQUu-idh24eS\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUBf4ni2ZPs3"
      },
      "source": [
        "4. Generate API Keys  \n",
        "\n",
        "  Click the \"Create API key\" button. You will see two options:  \n",
        "- The first option, **\"Create API key in new project\"**, will create a new GCP (Google Cloud Platform) project and generate a new key.  \n",
        "- The second option allows you to select an existing GCP project where the key will be created, if you've used GCP before.  \n",
        "\n",
        "If this is your first time using GCP, select the first option.\n",
        "\n",
        "<img src=\"https://lh3.google.com/u/0/d/1yhNB5BT6Wtobxjhlb9cAJ4FGUv75CG3p\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoAI4YYoanrs"
      },
      "source": [
        "5. Copy the Google Gemini API key.\n",
        "\n",
        "<img src=\"https://lh3.google.com/u/0/d/1J9sO5UMCz_ylNO27ku8vJr9_rKp63k5T\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter your API Key for this Colab"
      ],
      "metadata": {
        "id": "fxb0I88A-9GP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bP1KJB99Tsff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de37db79-2534-4dcf-f3ae-db07b8b29f57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "api_key = getpass.getpass(\"Enter your Google AI API key: \")\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The LLM Model we're going to use"
      ],
      "metadata": {
        "id": "Q-ONN7Az_NV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=1.0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "kzGMS0Awtui9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limitations of Language Models"
      ],
      "metadata": {
        "id": "dwmU99P_lp-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hallucinations\n",
        "\n",
        "Language models sometimes generate responses that appear plausible but are factually incorrect or entirely fabricated. This phenomenon, known as \"hallucination,\" can mislead users, especially in contexts requiring high accuracy, such as medical, legal, or technical fields."
      ],
      "metadata": {
        "id": "Q4FBpIDHslNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's try in legel fields\n",
        "\n",
        "Truth is, **there is no Article 1226 in Civil Code**, we can verify it here. [Link here](https://law.moj.gov.tw/LawClass/LawSearchCNKey.aspx?BTNType=NO&pcode=B0000001)\n",
        "\n"
      ],
      "metadata": {
        "id": "ypEI95rdxfAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    (\"human\", \"What is the specific content of Article 1226 in the Civil Code(民法) of Taiwan? Reply in Chinese.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arVmZri6sqSg",
        "outputId": "48868aec-e5fd-4005-80c3-764cf390ece8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "台灣民法第1226條的內容是：\n",
            "\n",
            "**特留分，依左列各款之規定：**\n",
            "\n",
            "*   **一、直系血親卑親屬之特留分，為其應繼分之二分之一。**\n",
            "*   **二、父母之特留分，為其應繼分之二分之一。**\n",
            "*   **三、配偶之特留分，為其應繼分之二分之一。**\n",
            "*   **四、兄弟姊妹之特留分，為其應繼分之三分之一。**\n",
            "*   **五、祖父母之特留分，為其應繼分之三分之一。**\n",
            "\n",
            "**特留分被侵害時，繼承人得行使扣減權。**\n",
            "\n",
            "**解釋：**\n",
            "\n",
            "這條法律規定了台灣民法中關於「特留分」的規定，明確指出了各順位繼承人所享有的最低繼承比例，也就是即使被繼承人透過遺囑或其他方式分配財產，仍然需要保留給特定親屬的最低保障份額。  如果實際繼承的財產少於特留分，繼承人可以行使「扣減權」，要求受益人返還超出部分的財產。\n",
            "\n",
            "總之，Article 1226 of Taiwan's Civil Code defines the reserved portion (特留分) of inheritance for different relatives, ensuring a minimum inheritance even when a will exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge cut-off\n",
        "\n",
        "The knowledge of a language model is limited to the data it was trained on, up to a specific cut-off date. As a result, it cannot provide information about events, discoveries, or updates that occurred after that point, making it less reliable for addressing recent developments."
      ],
      "metadata": {
        "id": "q8aOS9jdsj2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLMs won't know about things that happened recently\n",
        "\n",
        "The 47th United States presidential election took place on **November 5, 2024**.\n",
        "\n",
        "The model we're using, `gemini-2.0-flash`, knowledge cutoff at **June 2024** ([see more about model](https://deepmind.google/technologies/gemini/flash/))"
      ],
      "metadata": {
        "id": "PHCCy6Mc3WEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    (\"human\", \"Who won the 47th US President election?\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "id": "c6F8jNzVsqz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c93305-3f34-47ec-fdb9-62083922bfd1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There was not a 47th US Presidential election. Joe Biden is the 46th and current President of the United States.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's build RAG to slove it!"
      ],
      "metadata": {
        "id": "i3Sf_Wmb4gA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Knowledge we want LLM to know\n",
        "\n",
        "These are news reports about events that occurred between late 2024 and early 2025, which the LLM is not yet aware have taken place.\n",
        "\n",
        "1. [Trump seeks to force TSMC negotiations, experts say](https://www.taipeitimes.com/News/biz/archives/2025/02/10/2003831601) - 專家：川普試圖迫使台積電進行談判\n",
        "2. [Instagram ‘Teen Accounts’ go live in Taiwan today](https://www.taipeitimes.com/News/taiwan/archives/2025/02/11/2003831708) - Instagram「青少年帳號」今日在台灣上線\n",
        "3. [Donald Trump wins US presidency](https://www.taipeitimes.com/News/front/archives/2024/11/07/2003826511) - 川普當選美國總統\n",
        "4. [Team Taiwan claim U-12 Asian baseball title](https://www.taipeitimes.com/News/front/archives/2024/11/30/2003827724) - 台灣隊奪得U-12亞洲棒球錦標賽冠軍\n",
        "5. [What is DeepSeek and why is it disrupting the AI sector?](https://www.taipeitimes.com/News/lang/archives/2025/02/11/2003831649) - 什麼是DeepSeek？為何它正在顛覆AI產業？"
      ],
      "metadata": {
        "id": "YpAHep1j8IjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web Scraping these Knowledge\n",
        "\n",
        "Use web scraping on the five news articles mentioned above to extract the textual content of the reports."
      ],
      "metadata": {
        "id": "iIXaxmPlEtRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "os.environ['USER_AGENT'] = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "\n",
        "# Load and chunk contents\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\n",
        "        \"https://www.taipeitimes.com/News/biz/archives/2025/02/10/2003831601\",\n",
        "        \"https://www.taipeitimes.com/News/taiwan/archives/2025/02/11/2003831708\",\n",
        "        \"https://www.taipeitimes.com/News/front/archives/2024/11/07/2003826511\",\n",
        "        \"https://www.taipeitimes.com/News/front/archives/2024/11/30/2003827724\",\n",
        "        \"https://www.taipeitimes.com/News/lang/archives/2025/02/11/2003831649\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "assert len(docs) == 5\n",
        "\n",
        "print(\"Finished crawing news form urls.\")\n",
        "\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"News {i + 1}:\")\n",
        "    print(f\"  Source URL: {doc.metadata['source']}\")\n",
        "    print(f\"  Total Characters: {len(doc.page_content.strip())}\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7E1c4Tj8dfT",
        "outputId": "cf1d5fe6-189e-463a-d831-107d27d10696"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished crawing news form urls.\n",
            "News 1:\n",
            "  Source URL: https://www.taipeitimes.com/News/biz/archives/2025/02/10/2003831601\n",
            "  Total Characters: 8311\n",
            "------------------------------\n",
            "News 2:\n",
            "  Source URL: https://www.taipeitimes.com/News/taiwan/archives/2025/02/11/2003831708\n",
            "  Total Characters: 6914\n",
            "------------------------------\n",
            "News 3:\n",
            "  Source URL: https://www.taipeitimes.com/News/front/archives/2024/11/07/2003826511\n",
            "  Total Characters: 8531\n",
            "------------------------------\n",
            "News 4:\n",
            "  Source URL: https://www.taipeitimes.com/News/front/archives/2024/11/30/2003827724\n",
            "  Total Characters: 7223\n",
            "------------------------------\n",
            "News 5:\n",
            "  Source URL: https://www.taipeitimes.com/News/lang/archives/2025/02/11/2003831649\n",
            "  Total Characters: 10838\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting and Chunking Data\n",
        "\n",
        "There is too much characters here, and providing all of it to the LLM at once is not a good choice. Therefore, we need to break those into smaller chunks while preserving the semantics.\n",
        "\n",
        "- `chunk_size`: The maximum size of each chunk.\n",
        "- `chunk_overlap`: The number of overlapping characters between consecutive chunks. This ensures semantic continuity across chunks and prevents loss of context."
      ],
      "metadata": {
        "id": "2Z0PZeYyAf3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # chunk size (characters)\n",
        "    chunk_overlap=200,  # chunk overlap (characters)\n",
        "    add_start_index=True,  # track index in original document\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"Split all news into {len(all_splits)} sub-documents.\")"
      ],
      "metadata": {
        "id": "cfIAYAvnAa6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f1ebf3-bb1b-4aac-f658-ae65960df6c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split all news into 65 sub-documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Embedding Model\n",
        "\n",
        "The Embedding Model can convert the semantics of a sentence into a high-dimensional vector."
      ],
      "metadata": {
        "id": "y9yIzEq1GBlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "\n",
        "print(embeddings.embed_query(\"What's our Q1 revenue?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTlEWXTUGEcF",
        "outputId": "744fbfe8-5266-4229-9e63-adf0a9906a68"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.040674030780792236, 0.006255019456148148, -0.013568978756666183, -0.0003686861018650234, 0.04303165152668953, 0.04935013875365257, -0.013514830730855465, -0.027903610840439796, -0.03995805233716965, -0.006844368763267994, 0.0013024156214669347, -0.009539234451949596, 0.0705987736582756, -0.009862210601568222, 0.03167127072811127, -0.02663198858499527, -0.018167555332183838, -0.005245935637503862, -0.14866198599338531, -0.01596848852932453, 0.02811194583773613, -0.0018506837077438831, -0.025303209200501442, -0.01434125192463398, -0.03104301728308201, -0.07088255137205124, 0.011673162691295147, 0.008746510371565819, 0.003015926806256175, -0.010475549846887589, -6.184780795592815e-05, -0.0014338439796119928, -0.03641575202345848, -0.0519932359457016, -0.02123081497848034, 0.03613690286874771, -0.03694721683859825, 0.06530386954545975, 0.031148776412010193, -0.05865824222564697, -0.033094197511672974, -0.002400598954409361, -0.039360735565423965, 0.001522441511042416, 0.03487030044198036, 0.0026657148264348507, -0.0058933584950864315, 0.020132659003138542, -0.0036536972038447857, 0.008130554109811783, -0.009108034893870354, -0.03555028885602951, -0.014387637376785278, 0.0020767864771187305, -0.047531772404909134, -0.023021064698696136, 0.02736302837729454, -0.026102488860487938, 0.08498480916023254, -0.009469239041209221, 0.0319310761988163, -0.0018667412223294377, 0.059389110654592514, -0.0035042506642639637, 0.020587773993611336, -0.03917128965258598, 0.03360649570822716, 0.015973566100001335, -0.0738484337925911, -0.02538050338625908, -0.02277788706123829, 0.05237537994980812, 0.011328230611979961, -0.03981751948595047, -0.0006608059629797935, -0.008069388568401337, 0.007512678857892752, -0.04804745689034462, 0.03459799289703369, 0.08978776633739471, -0.07167279720306396, 0.022603409364819527, 0.08019706606864929, 0.00940668024122715, 0.03418527916073799, -0.015340480022132397, -0.03552362322807312, -0.03181988373398781, -0.05383983999490738, -0.04403817653656006, 0.05618930980563164, -0.02780766971409321, -0.02107255905866623, -0.018637580797076225, 0.0897323489189148, -0.06604108214378357, -0.09660559147596359, -0.05220397189259529, 0.07147490233182907, 0.06639932841062546, 0.004779261536896229, -0.03112303651869297, 0.0008881306857801974, 0.01845836080610752, 0.0274297297000885, 0.0004622933629434556, -0.03492116928100586, -0.004169788211584091, -0.021554481238126755, -0.02542758919298649, -0.02286696434020996, -0.03512721508741379, 0.0026910000015050173, -0.028166597709059715, 0.004026286769658327, -0.00791264045983553, -0.024778082966804504, 0.015024474821984768, -0.010839731432497501, 0.009473622776567936, 0.056382134556770325, 0.021171119064092636, -0.008079694584012032, 0.025672005489468575, 0.028384380042552948, 0.020231332629919052, 0.0428866408765316, -0.0007346387719735503, -0.03555949404835701, -0.05524420365691185, -0.014625327661633492, 0.009426695294678211, 0.010897071100771427, -0.003945027478039265, 0.022394057363271713, -0.024528535082936287, 0.0876956656575203, 0.04642253741621971, -0.030577486380934715, 0.03828105702996254, 0.03191431239247322, -0.04186468943953514, -0.06275169551372528, 0.014168639667332172, -0.01498769223690033, -0.024832768365740776, 0.027766933664679527, -0.0004999113152734935, -0.025478815659880638, -0.03067292645573616, -0.027004195377230644, 0.005373257678002119, -0.005426143296062946, -0.013760142959654331, 0.047259990125894547, -3.351004352225573e-06, 0.011196448467671871, 0.0331735797226429, 0.04530906677246094, 0.026219498366117477, -0.03507794439792633, 0.013839093036949635, -0.02348119020462036, 0.028220539912581444, -0.039287421852350235, 0.023950839415192604, -0.02938219904899597, -0.003724222769960761, 0.03192543610930443, 0.0069425287656486034, -0.02548467367887497, -0.03700289875268936, -0.053304944187402725, -0.06592298299074173, -0.01140379998832941, 0.07297323644161224, -0.010483955964446068, -0.04604703560471535, -0.12386089563369751, -0.05467037111520767, 0.03335092216730118, 0.013243228197097778, -0.05039249360561371, -0.008832715451717377, 0.06478633731603622, 0.04017411917448044, 0.0036366560962051153, -0.026531219482421875, -0.015908753499388695, 0.006120656616985798, -0.01062320638448, 0.005162350367754698, 0.032537247985601425, -0.042312879115343094, 0.017654040828347206, 0.05063820630311966, 0.042538005858659744, -0.03213687241077423, -0.038917768746614456, 0.010565686970949173, -0.010164313018321991, -0.029124340042471886, 0.028939809650182724, -0.046825725585222244, -0.04041363671422005, -0.02851947396993637, -0.05352668836712837, -0.023540807887911797, -0.05905939266085625, 0.006182074546813965, 0.0236660148948431, 0.01643635518848896, -0.055969204753637314, -0.052113115787506104, 0.005142379552125931, 0.015834525227546692, 0.07765226811170578, 0.014419138431549072, 0.014757545664906502, -0.016682716086506844, 0.035169124603271484, -0.012445286847651005, 0.04094401374459267, -0.0004567909345496446, 0.03075295127928257, 0.015191249549388885, 0.0008787462138570845, 0.011183375492691994, -0.02541988343000412, -0.01335611566901207, 0.04078405350446701, 0.00097758905030787, -0.027971843257546425, 0.03310989588499069, -0.036995869129896164, 0.07041022926568985, 0.038847681134939194, 0.011135242879390717, 0.0178934745490551, -0.06709057837724686, -0.018150683492422104, -0.004681224934756756, -0.020785439759492874, -0.0015118676237761974, -0.01593458652496338, 0.008007141761481762, 0.056374192237854004, 0.018349969759583473, -0.01836358942091465, -0.03326503559947014, -0.062389075756073, 0.012848050333559513, -0.0030290777795016766, 0.00806711707264185, -0.06129119545221329, -0.009198661893606186, 0.0034411519300192595, -0.05829843878746033, 0.017203867435455322, 0.07828714698553085, 0.02788754366338253, -0.05472508445382118, -0.0053860764019191265, -0.04209680110216141, -0.057854652404785156, -0.06215570494532585, -0.037162765860557556, -0.026187805458903313, 0.013729006983339787, 0.00522513035684824, 0.007254887372255325, 0.007314743008464575, -0.044295214116573334, 0.012690248899161816, 0.0015951964305713773, -0.020993180572986603, -0.028973281383514404, 0.01797867938876152, -0.03705243021249771, 0.016344338655471802, 0.047140851616859436, -0.0045312875881791115, 0.020043889060616493, -0.04180380329489708, 0.008862539194524288, 0.011784982867538929, 0.012936141341924667, 0.04847110062837601, 0.020518505945801735, -0.04009382799267769, 0.004235445521771908, -0.015121255069971085, -0.017107676714658737, -0.0022628495935350657, 0.03131377324461937, 0.058326173573732376, 0.047612544149160385, 0.0008990900823846459, 0.012505724094808102, 0.0234519150108099, 0.011617792770266533, 0.0089767687022686, 0.012201692909002304, 0.05818939581513405, 0.07964139431715012, 0.02628134936094284, 0.0035562783014029264, -0.06586579233407974, -0.06682974845170975, -0.004343168810009956, 0.024766702204942703, -0.045907892286777496, -0.024228105321526527, -0.04364803433418274, -0.01721922867000103, -0.014083858579397202, -0.08534359931945801, -0.022292688488960266, -0.035723213106393814, -0.05347568914294243, 0.04860648512840271, -0.024981264024972916, -0.05546209588646889, -0.02599288523197174, 0.059800885617733, 0.027545634657144547, 0.010634008795022964, 0.030378857627511024, -0.06266247481107712, -0.02802923507988453, -0.0164673812687397, -0.00466604670509696, 0.0068775867111980915, -0.04135647043585777, 0.013757770881056786, 0.030090903863310814, -0.051660291850566864, 0.035671450197696686, 0.05833543464541435, 0.030305322259664536, 0.030703585594892502, 0.045433782041072845, 0.035327911376953125, 0.04064740985631943, -0.02929910458624363, 0.0028224694542586803, 0.04217402637004852, 0.017522307112812996, -0.02317088656127453, -0.012836667709052563, 0.016060883179306984, 0.07096286863088608, 0.022300882264971733, -0.030652055516839027, -0.02046220190823078, -0.008860406465828419, 0.044191617518663406, 0.012760547921061516, 0.017109554260969162, 0.00567222386598587, 0.020018693059682846, -0.015990694984793663, -0.03650399297475815, -0.010141105391085148, -0.024074191227555275, 0.03260262683033943, 0.01904658041894436, 0.03513059765100479, -0.012212435714900494, 0.0036663140635937452, -0.0070173488929867744, -0.03424908220767975, 0.036729518324136734, 0.01946347951889038, -0.00860413908958435, -0.04971911385655403, -0.059182457625865936, -0.002848780946806073, 0.031969111412763596, -0.026185661554336548, 0.05550776794552803, -0.004006619565188885, -0.051209691911935806, 0.06815080344676971, -0.05306592956185341, 0.020680462941527367, -0.07201379537582397, -0.01924624852836132, 0.005424595437943935, -0.043159838765859604, -0.004355010110884905, -0.0022963096853345633, 0.028794437646865845, 0.030889587476849556, -0.007004606071859598, 0.07111821323633194, -0.013412009924650192, -0.014901253394782543, 0.014481945894658566, -0.038996364921331406, -0.03584769740700722, -0.0066221775487065315, 0.008168015629053116, -0.03866076096892357, -0.024964667856693268, -0.03399388864636421, 0.07047809660434723, -0.002807113341987133, -0.0026940142270177603, -0.02858911268413067, 0.06441131234169006, 0.022924337536096573, -0.038946185261011124, -0.005655820947140455, -0.05000632628798485, -0.014447260648012161, -0.002026891801506281, 0.0030106124468147755, 0.05433937534689903, 0.0038927753921598196, 0.01058945618569851, -0.020083194598555565, 0.06434295326471329, -0.037731949239969254, 0.019364971667528152, -0.01708812639117241, -0.007275398354977369, 0.006923719309270382, 0.03294694796204567, 0.008821401745080948, -0.035904500633478165, 0.023028215393424034, -0.028629709035158157, -0.012202284298837185, -0.07996783405542374, 0.009951084852218628, -0.018842991441488266, 0.04279767721891403, 0.0063218362629413605, -0.020923594012856483, 0.01167957205325365, 0.02149077132344246, 0.04855334386229515, 0.01931636407971382, -0.00798702146857977, 0.005307495128363371, -0.010870776139199734, 0.02465776912868023, -0.05784374848008156, -0.012009432539343834, -0.0010353594552725554, 0.001357968314550817, 0.03233030438423157, -0.03482642024755478, -0.04115253686904907, -0.0016379851149395108, -0.016736943274736404, 0.03030269965529442, 0.0070823547430336475, 0.013011662289500237, 0.0013094530440866947, -0.023420250043272972, 0.04642616957426071, 0.04938816651701927, 0.011798360385000706, -0.045309584587812424, 0.009469387121498585, -0.005720063112676144, -0.005492646712809801, 0.07672107964754105, 0.05767561495304108, -0.016651729121804237, 0.01272104773670435, -0.028916891664266586, -0.01569833792746067, 0.013438977301120758, -0.04521883279085159, -0.04580063745379448, -0.06875801086425781, -0.008748088032007217, 0.0034978643525391817, -0.05619722977280617, -0.046840690076351166, 0.049902353435754776, 0.03386502340435982, -0.008411991409957409, -0.003451331052929163, -0.02074151486158371, 0.07574094086885452, -0.01795017346739769, 0.015205703675746918, 0.020769039168953896, -0.0004893033183179796, -0.04977618157863617, -0.06083740293979645, -0.011869067326188087, 0.04016096889972687, -0.0056722043082118034, -0.02773195691406727, 0.01636294275522232, 0.01701270416378975, 0.03908716142177582, -0.015088760294020176, -0.03776533156633377, -0.02017400600016117, -0.05718950182199478, -0.04964404180645943, -0.008687540888786316, -0.00674031674861908, -0.009721371345221996, 0.00877001229673624, -0.04894879087805748, 0.029544781893491745, 0.0656760111451149, 0.01786809228360653, 0.03679507598280907, -0.048695698380470276, 0.05084334313869476, -0.0012932618847116828, -0.014733269810676575, -0.0942688137292862, -0.005923083983361721, 0.0548890121281147, -0.0027005928568542004, 0.026992907747626305, -0.00731872720643878, -0.06826119124889374, -0.02900216169655323, 0.004012713208794594, 0.013650557026267052, 0.02704375982284546, 0.03710830584168434, 0.033099979162216187, 0.01301198173314333, -0.05733863264322281, 0.025459110736846924, 0.024094557389616966, -0.007090229541063309, -0.025551943108439445, 0.036184437572956085, 0.038272250443696976, -0.027310671284794807, 0.027453413233160973, 0.038615234196186066, 0.02579406090080738, 0.05250363424420357, 0.022117899730801582, -0.05710281804203987, -0.0017957596573978662, 0.03591448813676834, -0.005846180021762848, -0.06997204571962357, 0.00024452630896121264, -0.010681462474167347, 0.06773526221513748, -0.005376582033932209, 0.022301286458969116, 0.022317348048090935, 0.012877714820206165, -0.04674927517771721, 0.05696335807442665, -0.01296178437769413, 0.016913650557398796, -0.053046829998493195, -0.002701016841456294, 0.003923126962035894, 0.03747446462512016, 0.11272288858890533, -0.0015829706098884344, -0.05584847927093506, 0.09707442671060562, -0.00024738904903642833, -0.03714948520064354, -0.04195793718099594, 0.009514124132692814, 0.019299393519759178, -0.03335732966661453, 0.0021547258365899324, 0.053686920553445816, -0.03058801032602787, -0.0028617610223591328, 0.03269273787736893, 0.02336142770946026, -0.018097469583153725, -0.020934492349624634, 0.03093210980296135, -0.008286625146865845, -0.029237965121865273, -0.03758196532726288, -0.02840360254049301, 0.053243815898895264, 0.010723110288381577, -0.020957577973604202, -0.022098371759057045, 0.06305725127458572, -0.023262832313776016, 0.01595097780227661, 0.00835984107106924, 0.07245082408189774, 0.008686445653438568, 0.0012503870530053973, 7.557651406386867e-05, 0.03862207755446434, -0.019229695200920105, 0.014497706666588783, 0.012569671496748924, -0.026799125596880913, 0.019178958609700203, 0.026653669774532318, -0.014713150449097157, -0.00043338595423847437, 0.08456723392009735, -0.062270551919937134, 0.008901653811335564, -0.0008224630146287382, -0.009016134776175022, 0.010196023620665073, -0.05758286267518997, 0.001213831827044487, -0.012950764037668705, 0.08539506793022156, -0.01374772097915411, 0.03781634569168091, -0.015076442621648312, -0.0145783182233572, -0.012429311871528625, -0.05112070590257645, 0.042674072086811066, -0.03859506547451019, 0.0258342158049345, -0.0033613459672778845, -0.008885742165148258, 0.009936174377799034, 0.008650175295770168, -0.030997151508927345, 0.02414288930594921, 0.019081875681877136, 0.021299712359905243, -0.0016012733103707433, -0.03776213154196739, -0.007063841447234154, -0.010149193927645683, 0.018930433318018913, -0.030712800100445747, -0.0070159053429961205, -0.016985133290290833, 0.07048439234495163, 0.004174362868070602, -0.0022258968092501163, -0.02214689739048481, 0.027761224657297134, 0.034946225583553314, -0.044282216578722, -0.034360796213150024, -0.03490037843585014, 0.018017347902059555, -0.04288153350353241, 0.08776484429836273, 0.036676447838544846, -0.004171433392912149, -0.023275645449757576, -0.07430888712406158, -0.05915144830942154, 0.09232326596975327, -0.025909466668963432, -0.048947375267744064, -0.04248259216547012, -0.008888361044228077, -0.03014891780912876, -0.04645727202296257, -0.012320748530328274, -0.05791699141263962, -0.031029148027300835, -0.008003050461411476, 0.06263463944196701, -0.0003443692403379828, -0.0023389095440506935, -0.024600928649306297, -0.012160244397819042, 0.024075577035546303, 0.04455995932221413, -0.034846968948841095, 0.003009699983522296, -0.006747885141521692, 0.033100686967372894, 0.017554784193634987, 0.0066912914626300335, -0.03815562650561333, 0.03287581354379654, 0.008438421413302422, 0.05949356034398079, 0.05250370502471924, -0.025399159640073776, -0.00804033875465393, -0.0951286181807518, 0.04880988597869873, -0.030327320098876953, -0.00582280196249485, 0.06371273845434189, -0.008379978127777576, -0.01847619190812111, 0.0033510157372802496, -0.06536964327096939, -0.007209788542240858, 0.0060051498003304005, 0.00125016737729311, 0.0346645750105381, -0.0015321788378059864, -0.0008062190026976168, 0.012339606881141663, 0.004700178746134043, -0.014207116328179836, 0.048131342977285385, -0.028085095807909966, 0.0396636538207531, -0.026388678699731827, 0.02602994255721569, 0.005051842425018549, 0.061865344643592834, 0.07961132377386093, -0.03165215626358986, -0.019245469942688942, 0.047423698008060455, 0.029522284865379333, 0.0305622685700655, -0.04864562675356865, -0.05137154087424278, -0.03016076795756817, -0.010218193754553795, 0.02187609300017357, 0.06728222966194153, -0.058545537292957306, -0.07691137492656708, -0.04078034684062004, 0.02178112603724003, 0.004406917840242386, 0.01251312531530857, -0.01934864930808544, -0.00024852779461070895, -0.027734138071537018, 0.044431790709495544, 0.02758478745818138, 0.044154103845357895, -0.03837814927101135, 0.032868776470422745, 0.009355633519589901, -0.007741476874798536, -0.024058016017079353, -0.02246076613664627, -0.004031325690448284, -0.036114875227212906, 0.058158028870821, 0.0031521052587777376, 0.03671975061297417, -0.026520084589719772, -0.06631795316934586, 0.10039965808391571, -0.002299437765032053, -0.011070421896874905, -0.027540046721696854, 0.0407177172601223, 0.06292594969272614, 0.032785814255476, 0.021106448024511337, -0.04404228925704956, -0.005727207753807306, 0.06395310908555984, -0.007708157878369093]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Database\n",
        "\n",
        "In this tutorial, for the sake of convenience and speed, we will directly use RAM as the storage location for vector data."
      ],
      "metadata": {
        "id": "NGs95kWwAlev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "vector_store = InMemoryVectorStore(embeddings)"
      ],
      "metadata": {
        "id": "BMmzmhcEMy_2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save embedding into Vector DB"
      ],
      "metadata": {
        "id": "vO65V7e5At2s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UpIpIL3sSCYr"
      },
      "outputs": [],
      "source": [
        "# Index chunks\n",
        "_ = vector_store.add_documents(documents=all_splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Prompt\n",
        "\n",
        "This prompt is used in the generation stage of RAG, providing instructions to the LLM to generate a coherent and fluent response."
      ],
      "metadata": {
        "id": "Ha267eVgGmJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt for question-answering\n",
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "example_messages = prompt.invoke(\n",
        "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
        ").to_messages()\n",
        "\n",
        "assert len(example_messages) == 1\n",
        "print(example_messages[0].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8KJZ3gBGodi",
        "outputId": "668a0c1b-593d-4574-b736-e9f240d1a8fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: (question goes here) \n",
            "Context: (context goes here) \n",
            "Answer:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building RAG Workflow\n",
        "\n",
        "The RAG we are building will primarily consist of two steps: Retrieval and Generation.\n",
        "\n",
        " - **Retrieval:** The question is used to perform a vector search, retrieving the most semantically relevant sub-documents from the previously created sub-documents.\n",
        "\n",
        " - **Generation:** The content of the retrieved sub-documents is provided to the LLM, which generates a complete answer based on the question."
      ],
      "metadata": {
        "id": "X409ZJs_Gr8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from typing_extensions import List, TypedDict\n",
        "\n",
        "from langgraph.graph import START, StateGraph\n",
        "\n",
        "# Define state for application\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "\n",
        "\n",
        "# Define application steps\n",
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"answer\": response.content}\n",
        "\n",
        "\n",
        "# Compile application and test\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "D8oxnd9FGugB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Done! Let's try it!"
      ],
      "metadata": {
        "id": "DhC2Zti_YTD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some question you can try\n",
        "\n",
        "```plaintext\n",
        "Who was elected the 47th president of the United States?\n",
        "```\n",
        "\n",
        "```plaintext\n",
        "What is the purpose of Trump's proposed tariffs on Taiwanese semiconductors?\n",
        "```\n",
        "\n",
        "```plaintext\n",
        "What is DeepSeek, and why is it significant in the AI sector?\n",
        "```\n",
        "\n",
        "```plaintext\n",
        "What impact has DeepSeek’s success had on big tech companies like Nvidia?\n",
        "```"
      ],
      "metadata": {
        "id": "Co_I7w8jGz0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"Who was elected the 47th president of the United States?\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfg4i1K5G4N9",
        "outputId": "e1297c42-603d-4dce-fe5b-3dc7076836ae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Donald Trump was elected the 47th president of the US. He secured 277 electoral votes, surpassing the 270 needed to win the presidency. He defeated the Democratic Party’s nominee, US Vice President Kamala Harris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying harder question\n",
        "\n",
        "This RAG we built is quite smart; you can try more questions in the `news-QA-dataset.json` file.\n",
        "\n",
        "#### About 2024 Asian Baseball Championship Final\n",
        "\n",
        "```plaintext\n",
        "What was the score of Taiwan’s loss to South Korea in division B?\n",
        "```\n",
        "\n",
        "```plaintext\n",
        "What action by South Korea’s pitcher allowed Su Yu-hsiang to steal second base in the final?\n",
        "```"
      ],
      "metadata": {
        "id": "6bBrzq80SaVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"What was the score of Taiwan’s loss to South Korea in division B?\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBvwKkhGTBdD",
        "outputId": "c0962f1c-4763-45b6-cd3e-0fdbb8cbc5a8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taiwan lost to South Korea 0-1 in division B. However, Taiwan later defeated South Korea 5-1 in the final to win the U-12 Asian Baseball Championship. The team secured two wins and one loss to finish second in division B.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Use Case Overview\n",
        "\n",
        "At this stage, we have successfully enabled the LLM to access the database we created and respond to queries based on the retrieved data.\n",
        "\n",
        "However, for **public data** such as news searches, implementing RAG is not always necessary. Existing LLM products, such as ChatGPT, already integrate web search functionalities, allowing them to directly retrieve real-time public information.\n",
        "\n",
        "### Key Insight: When to Use RAG\n",
        "The **primary use case for RAG** lies in handling **enterprise data** or **offline data**. These types of **non-public data** are more suitable for RAG as a supplementary source for LLMs."
      ],
      "metadata": {
        "id": "94rI1kgnqdrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enable Web Search Functionalities\n",
        "\n",
        "Google's LLM Also Comes with Built-in Web Search Functionality\n",
        "\n",
        "You can directly try this option in [Studio](https://aistudio.google.com/). However, here we will try it out using code instead."
      ],
      "metadata": {
        "id": "7w_sgN-9sXuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Building Library\n",
        "#@markdown Enable the GoogleSearchRetrieval tool feature using the Google Gen AI SDK.\n",
        "\n",
        "%%capture\n",
        "!pip install google-genai\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "def query_google_genai(question):\n",
        "    \"\"\"\n",
        "    Queries Google GenAI with a given question and returns the result.\n",
        "    This function uses the GoogleSearchRetrieval tool to perform a web search.\n",
        "\n",
        "    Parameters:\n",
        "        question (str): The question to query.\n",
        "\n",
        "    Returns:\n",
        "        str: The text content of the query result.\n",
        "    \"\"\"\n",
        "    # Initialize the GenAI client\n",
        "    client = genai.Client()\n",
        "\n",
        "    # Send the query request\n",
        "    response = client.models.generate_content(\n",
        "        model='gemini-2.0-flash',\n",
        "        contents=question,\n",
        "        config=types.GenerateContentConfig(\n",
        "            tools=[types.Tool(\n",
        "                google_search=types.GoogleSearchRetrieval\n",
        "            )]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Process the response and return the result\n",
        "    if response.candidates:\n",
        "        first_candidate = response.candidates[0]\n",
        "        if first_candidate.content and first_candidate.content.parts:\n",
        "            return first_candidate.content.parts[0].text\n",
        "\n",
        "    # Return a default message if no valid response is received\n",
        "    return \"No valid response received.\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "DYacQKA2uECl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gemini Now Performs Web Searches Before Answering\n",
        "\n",
        "Now it will say \"I don't know\" instead of fabricating a non-existent law.  \n",
        "\n",
        "Therefore, the primary benefit of RAG is to **significantly reduce hallucinations**."
      ],
      "metadata": {
        "id": "bQPFpZBhrsAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the specific content of Article 1226 in the Civil Code(民法) of Taiwan? Reply in Chinese.\"\n",
        "\n",
        "result = query_google_genai(question)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "YvFtzmICwtPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23c6a6e-0623-4af5-f903-c5ba84f3455e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unfortunately, I am unable to find the exact content of Article 1226 in the Civil Code of Taiwan. The search results provide information regarding Article 1226 in the Civil Code of France and some general information regarding obligations with penal clauses.\n",
            "\n",
            "To find the specific content of Article 1226 in Taiwan's Civil Code, you can try the following:\n",
            "\n",
            "*   Consult a legal database of Taiwanese laws.\n",
            "*   Search the official website of Taiwan's Ministry of Justice.\n",
            "*   Consult with a legal professional familiar with Taiwanese law.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}